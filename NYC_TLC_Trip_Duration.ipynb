{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sushant6862/Jeremy-Howard-Squadron-/blob/main/NYC_TLC_Trip_Duration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install xgboost lightgbm catboost"
      ],
      "metadata": {
        "id": "PU2zCfWnKcte",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18cbc699-3f5c-443c-bd72-8fdce95d8f6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.10/dist-packages (4.1.0)\n",
            "Collecting catboost\n",
            "  Downloading catboost-1.2.2-cp310-cp310-manylinux2014_x86_64.whl (98.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.11.4)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.5.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2023.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.48.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.1.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (8.2.3)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-1.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bTiAGwzZJRG5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b827d0f-abfc-492e-bc5c-e1ecb4d5f7d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-9f99b4999f63>:4: DeprecationWarning: `np.math` is a deprecated alias for the standard library `math` module (Deprecated Numpy 1.25). Replace usages of `np.math` with `math`\n",
            "  from numpy import math\n"
          ]
        }
      ],
      "source": [
        "# Importing the libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from numpy import math\n",
        "#from haversine import haversine\n",
        "import xgboost\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.linear_model import Ridge\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "#import klib\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import warnings\n",
        "from pylab import rcParams\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns; sns.set()\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nyc_tlc = pd.read_parquet('/content/drive/MyDrive/DataSets/yellow_tripdata_2023-11.parquet',engine='pyarrow')"
      ],
      "metadata": {
        "id": "bgOTI_bhK2wl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nyc_tlc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "qStFJMfBLXj8",
        "outputId": "1ab1af2c-f071-44df-8422-ee78d4daf199"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
              "0               1  2023-11-01 00:03:03   2023-11-01 01:04:08              2.0   \n",
              "1               1  2023-11-01 00:03:28   2023-11-01 00:23:59              0.0   \n",
              "2               2  2023-10-31 23:58:05   2023-11-01 00:54:03              4.0   \n",
              "3               2  2023-11-01 00:03:50   2023-11-01 00:04:59              1.0   \n",
              "4               2  2023-11-01 00:06:30   2023-11-01 00:14:25              1.0   \n",
              "...           ...                  ...                   ...              ...   \n",
              "3339710         2  2023-11-30 23:39:21   2023-12-01 00:05:10              NaN   \n",
              "3339711         2  2023-11-30 23:01:55   2023-11-30 23:03:06              NaN   \n",
              "3339712         2  2023-11-30 23:23:16   2023-11-30 23:33:56              NaN   \n",
              "3339713         2  2023-11-30 23:39:22   2023-11-30 23:53:33              NaN   \n",
              "3339714         2  2023-11-30 23:13:48   2023-11-30 23:37:11              NaN   \n",
              "\n",
              "         trip_distance  RatecodeID store_and_fwd_flag  PULocationID  \\\n",
              "0                13.60         1.0                  N           132   \n",
              "1                 3.50         1.0                  N           140   \n",
              "2                18.61         2.0                  N           132   \n",
              "3                 0.39         1.0                  N           236   \n",
              "4                 1.20         1.0                  N           236   \n",
              "...                ...         ...                ...           ...   \n",
              "3339710           4.15         NaN               None           161   \n",
              "3339711           0.00         NaN               None           232   \n",
              "3339712           1.74         NaN               None           113   \n",
              "3339713           2.39         NaN               None            90   \n",
              "3339714           3.38         NaN               None           114   \n",
              "\n",
              "         DOLocationID  payment_type  fare_amount  extra  mta_tax  tip_amount  \\\n",
              "0                  26             2        61.80   2.75      0.5        0.00   \n",
              "1                   7             1        20.50   3.50      0.5        5.10   \n",
              "2                 230             1        70.00   0.00      0.5       16.54   \n",
              "3                 236             1         4.40   1.00      0.5        1.88   \n",
              "4                 141             1        10.00   1.00      0.5        3.00   \n",
              "...               ...           ...          ...    ...      ...         ...   \n",
              "3339710           146             0        24.30   0.00      0.5        5.66   \n",
              "3339711           232             0        22.42   0.00      0.5        5.14   \n",
              "3339712           186             0        16.09   0.00      0.5        0.00   \n",
              "3339713           144             0        16.23   0.00      0.5        0.00   \n",
              "3339714           142             0        27.95   0.00      0.5        0.00   \n",
              "\n",
              "         tolls_amount  improvement_surcharge  total_amount  \\\n",
              "0                0.00                    1.0         66.05   \n",
              "1                0.00                    1.0         30.60   \n",
              "2                6.94                    1.0         99.23   \n",
              "3                0.00                    1.0         11.28   \n",
              "4                0.00                    1.0         18.00   \n",
              "...               ...                    ...           ...   \n",
              "3339710          0.00                    1.0         33.96   \n",
              "3339711          0.00                    1.0         31.56   \n",
              "3339712          0.00                    1.0         20.09   \n",
              "3339713          0.00                    1.0         20.23   \n",
              "3339714          0.00                    1.0         31.95   \n",
              "\n",
              "         congestion_surcharge  Airport_fee  \n",
              "0                         0.0         1.75  \n",
              "1                         2.5         0.00  \n",
              "2                         2.5         1.75  \n",
              "3                         2.5         0.00  \n",
              "4                         2.5         0.00  \n",
              "...                       ...          ...  \n",
              "3339710                   NaN          NaN  \n",
              "3339711                   NaN          NaN  \n",
              "3339712                   NaN          NaN  \n",
              "3339713                   NaN          NaN  \n",
              "3339714                   NaN          NaN  \n",
              "\n",
              "[3339715 rows x 19 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-983ce729-b372-426e-8e99-d11446d919b8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>VendorID</th>\n",
              "      <th>tpep_pickup_datetime</th>\n",
              "      <th>tpep_dropoff_datetime</th>\n",
              "      <th>passenger_count</th>\n",
              "      <th>trip_distance</th>\n",
              "      <th>RatecodeID</th>\n",
              "      <th>store_and_fwd_flag</th>\n",
              "      <th>PULocationID</th>\n",
              "      <th>DOLocationID</th>\n",
              "      <th>payment_type</th>\n",
              "      <th>fare_amount</th>\n",
              "      <th>extra</th>\n",
              "      <th>mta_tax</th>\n",
              "      <th>tip_amount</th>\n",
              "      <th>tolls_amount</th>\n",
              "      <th>improvement_surcharge</th>\n",
              "      <th>total_amount</th>\n",
              "      <th>congestion_surcharge</th>\n",
              "      <th>Airport_fee</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2023-11-01 00:03:03</td>\n",
              "      <td>2023-11-01 01:04:08</td>\n",
              "      <td>2.0</td>\n",
              "      <td>13.60</td>\n",
              "      <td>1.0</td>\n",
              "      <td>N</td>\n",
              "      <td>132</td>\n",
              "      <td>26</td>\n",
              "      <td>2</td>\n",
              "      <td>61.80</td>\n",
              "      <td>2.75</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>66.05</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2023-11-01 00:03:28</td>\n",
              "      <td>2023-11-01 00:23:59</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.50</td>\n",
              "      <td>1.0</td>\n",
              "      <td>N</td>\n",
              "      <td>140</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>20.50</td>\n",
              "      <td>3.50</td>\n",
              "      <td>0.5</td>\n",
              "      <td>5.10</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>30.60</td>\n",
              "      <td>2.5</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2023-10-31 23:58:05</td>\n",
              "      <td>2023-11-01 00:54:03</td>\n",
              "      <td>4.0</td>\n",
              "      <td>18.61</td>\n",
              "      <td>2.0</td>\n",
              "      <td>N</td>\n",
              "      <td>132</td>\n",
              "      <td>230</td>\n",
              "      <td>1</td>\n",
              "      <td>70.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.5</td>\n",
              "      <td>16.54</td>\n",
              "      <td>6.94</td>\n",
              "      <td>1.0</td>\n",
              "      <td>99.23</td>\n",
              "      <td>2.5</td>\n",
              "      <td>1.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>2023-11-01 00:03:50</td>\n",
              "      <td>2023-11-01 00:04:59</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.39</td>\n",
              "      <td>1.0</td>\n",
              "      <td>N</td>\n",
              "      <td>236</td>\n",
              "      <td>236</td>\n",
              "      <td>1</td>\n",
              "      <td>4.40</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.88</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>11.28</td>\n",
              "      <td>2.5</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>2023-11-01 00:06:30</td>\n",
              "      <td>2023-11-01 00:14:25</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.20</td>\n",
              "      <td>1.0</td>\n",
              "      <td>N</td>\n",
              "      <td>236</td>\n",
              "      <td>141</td>\n",
              "      <td>1</td>\n",
              "      <td>10.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.5</td>\n",
              "      <td>3.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>18.00</td>\n",
              "      <td>2.5</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3339710</th>\n",
              "      <td>2</td>\n",
              "      <td>2023-11-30 23:39:21</td>\n",
              "      <td>2023-12-01 00:05:10</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.15</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>161</td>\n",
              "      <td>146</td>\n",
              "      <td>0</td>\n",
              "      <td>24.30</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.5</td>\n",
              "      <td>5.66</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>33.96</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3339711</th>\n",
              "      <td>2</td>\n",
              "      <td>2023-11-30 23:01:55</td>\n",
              "      <td>2023-11-30 23:03:06</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>232</td>\n",
              "      <td>232</td>\n",
              "      <td>0</td>\n",
              "      <td>22.42</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.5</td>\n",
              "      <td>5.14</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>31.56</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3339712</th>\n",
              "      <td>2</td>\n",
              "      <td>2023-11-30 23:23:16</td>\n",
              "      <td>2023-11-30 23:33:56</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.74</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>113</td>\n",
              "      <td>186</td>\n",
              "      <td>0</td>\n",
              "      <td>16.09</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>20.09</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3339713</th>\n",
              "      <td>2</td>\n",
              "      <td>2023-11-30 23:39:22</td>\n",
              "      <td>2023-11-30 23:53:33</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.39</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>90</td>\n",
              "      <td>144</td>\n",
              "      <td>0</td>\n",
              "      <td>16.23</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>20.23</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3339714</th>\n",
              "      <td>2</td>\n",
              "      <td>2023-11-30 23:13:48</td>\n",
              "      <td>2023-11-30 23:37:11</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.38</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>114</td>\n",
              "      <td>142</td>\n",
              "      <td>0</td>\n",
              "      <td>27.95</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>31.95</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3339715 rows × 19 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-983ce729-b372-426e-8e99-d11446d919b8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-983ce729-b372-426e-8e99-d11446d919b8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-983ce729-b372-426e-8e99-d11446d919b8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-53112d0e-d164-4477-a732-7c9240233aa7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-53112d0e-d164-4477-a732-7c9240233aa7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-53112d0e-d164-4477-a732-7c9240233aa7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_1ecf0db9-4b60-4d51-b852-5ce3881f4fb5\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('nyc_tlc')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_1ecf0db9-4b60-4d51-b852-5ce3881f4fb5 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('nyc_tlc');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "nyc_tlc"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nyc_tlc.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUnDMaVgLdXR",
        "outputId": "5e4b430e-a5a8-41e1-d83e-25a3e597031a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3339715 entries, 0 to 3339714\n",
            "Data columns (total 19 columns):\n",
            " #   Column                 Dtype         \n",
            "---  ------                 -----         \n",
            " 0   VendorID               int32         \n",
            " 1   tpep_pickup_datetime   datetime64[ns]\n",
            " 2   tpep_dropoff_datetime  datetime64[ns]\n",
            " 3   passenger_count        float64       \n",
            " 4   trip_distance          float64       \n",
            " 5   RatecodeID             float64       \n",
            " 6   store_and_fwd_flag     object        \n",
            " 7   PULocationID           int32         \n",
            " 8   DOLocationID           int32         \n",
            " 9   payment_type           int64         \n",
            " 10  fare_amount            float64       \n",
            " 11  extra                  float64       \n",
            " 12  mta_tax                float64       \n",
            " 13  tip_amount             float64       \n",
            " 14  tolls_amount           float64       \n",
            " 15  improvement_surcharge  float64       \n",
            " 16  total_amount           float64       \n",
            " 17  congestion_surcharge   float64       \n",
            " 18  Airport_fee            float64       \n",
            "dtypes: datetime64[ns](2), float64(12), int32(3), int64(1), object(1)\n",
            "memory usage: 445.9+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "traindata = nyc_tlc\n",
        "null_counts = traindata.isnull().sum()\n",
        "columns_with_null = null_counts[null_counts > 0]\n",
        "dtypes_of_columns_with_null = traindata[columns_with_null.index].dtypes\n",
        "\n",
        "# Create a DataFrame with two columns\n",
        "df_info = pd.DataFrame({'Null_Counts': null_counts[columns_with_null.index], 'Data_Types': dtypes_of_columns_with_null})\n",
        "\n",
        "# Display the DataFrame\n",
        "print(\"\\nCombined Information about Columns with Null Values:\")\n",
        "print(df_info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWUT63h-MCC3",
        "outputId": "67cd2b3c-f130-43b1-c0f8-5710bf4d5973"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Combined Information about Columns with Null Values:\n",
            "                      Null_Counts Data_Types\n",
            "passenger_count            132675    float64\n",
            "RatecodeID                 132675    float64\n",
            "store_and_fwd_flag         132675     object\n",
            "congestion_surcharge       132675    float64\n",
            "Airport_fee                132675    float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nyc_tlc.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M25EIypqN15r",
        "outputId": "34ead41e-24c2-4bc3-83dc-8e564ccf36dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['VendorID', 'tpep_pickup_datetime', 'tpep_dropoff_datetime',\n",
              "       'passenger_count', 'trip_distance', 'RatecodeID', 'store_and_fwd_flag',\n",
              "       'PULocationID', 'DOLocationID', 'payment_type', 'fare_amount', 'extra',\n",
              "       'mta_tax', 'tip_amount', 'tolls_amount', 'improvement_surcharge',\n",
              "       'total_amount', 'congestion_surcharge', 'Airport_fee'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #Calculate trip duration from pickup time to dropout time.\n",
        "# nyc_tlc['trip_duration'] = (nyc_tlc['tpep_dropoff_datetime'] - nyc_tlc['tpep_pickup_datetime']).dt.total_seconds()\n",
        "# columns_to_drop = ['tpep_pickup_datetime', 'tpep_dropoff_datetime','VendorID','store_and_fwd_flag','fare_amount','extra','mta_tax','tip_amount','tolls_amount','improvement_surcharge']\n",
        "# nyc_df = nyc_tlc.drop(columns=columns_to_drop)"
      ],
      "metadata": {
        "id": "_WuNk5xzO0nq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculate trip duration from pickup time to dropout time.\n",
        "nyc_tlc['trip_duration'] = (nyc_tlc['tpep_dropoff_datetime'] - nyc_tlc['tpep_pickup_datetime']).dt.total_seconds()\n",
        "columns_to_drop = ['tpep_pickup_datetime', 'tpep_dropoff_datetime','VendorID','PULocationID','store_and_fwd_flag','congestion_surcharge','fare_amount','extra','mta_tax','tip_amount','tolls_amount','improvement_surcharge']\n",
        "nyc_df = nyc_tlc.drop(columns=columns_to_drop)"
      ],
      "metadata": {
        "id": "eP3ESBMLzrTA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nyc_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "XygfsnVfPI5Q",
        "outputId": "0910f60d-6424-46da-aef1-63ce876e7f7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   passenger_count  trip_distance  RatecodeID  DOLocationID  payment_type  \\\n",
              "0              2.0          13.60         1.0            26             2   \n",
              "1              0.0           3.50         1.0             7             1   \n",
              "2              4.0          18.61         2.0           230             1   \n",
              "3              1.0           0.39         1.0           236             1   \n",
              "4              1.0           1.20         1.0           141             1   \n",
              "\n",
              "   total_amount  Airport_fee  trip_duration  \n",
              "0         66.05         1.75         3665.0  \n",
              "1         30.60         0.00         1231.0  \n",
              "2         99.23         1.75         3358.0  \n",
              "3         11.28         0.00           69.0  \n",
              "4         18.00         0.00          475.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-42001f8c-c972-4dc1-96bb-3c6cd869b467\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>passenger_count</th>\n",
              "      <th>trip_distance</th>\n",
              "      <th>RatecodeID</th>\n",
              "      <th>DOLocationID</th>\n",
              "      <th>payment_type</th>\n",
              "      <th>total_amount</th>\n",
              "      <th>Airport_fee</th>\n",
              "      <th>trip_duration</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.0</td>\n",
              "      <td>13.60</td>\n",
              "      <td>1.0</td>\n",
              "      <td>26</td>\n",
              "      <td>2</td>\n",
              "      <td>66.05</td>\n",
              "      <td>1.75</td>\n",
              "      <td>3665.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>3.50</td>\n",
              "      <td>1.0</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>30.60</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1231.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.0</td>\n",
              "      <td>18.61</td>\n",
              "      <td>2.0</td>\n",
              "      <td>230</td>\n",
              "      <td>1</td>\n",
              "      <td>99.23</td>\n",
              "      <td>1.75</td>\n",
              "      <td>3358.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.39</td>\n",
              "      <td>1.0</td>\n",
              "      <td>236</td>\n",
              "      <td>1</td>\n",
              "      <td>11.28</td>\n",
              "      <td>0.00</td>\n",
              "      <td>69.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.20</td>\n",
              "      <td>1.0</td>\n",
              "      <td>141</td>\n",
              "      <td>1</td>\n",
              "      <td>18.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>475.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-42001f8c-c972-4dc1-96bb-3c6cd869b467')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-42001f8c-c972-4dc1-96bb-3c6cd869b467 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-42001f8c-c972-4dc1-96bb-3c6cd869b467');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-36b98a67-f030-42b5-a00d-5536dc418011\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-36b98a67-f030-42b5-a00d-5536dc418011')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-36b98a67-f030-42b5-a00d-5536dc418011 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "nyc_df"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nyc_df=nyc_df.dropna()"
      ],
      "metadata": {
        "id": "wbdIFJtaPLMO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "traindata = nyc_df\n",
        "null_counts = traindata.isnull().sum()\n",
        "columns_with_null = null_counts[null_counts > 0]\n",
        "dtypes_of_columns_with_null = traindata[columns_with_null.index].dtypes\n",
        "\n",
        "# Create a DataFrame with two columns\n",
        "df_info = pd.DataFrame({'Null_Counts': null_counts[columns_with_null.index], 'Data_Types': dtypes_of_columns_with_null})\n",
        "\n",
        "# Display the DataFrame\n",
        "print(\"\\nCombined Information about Columns with Null Values:\")\n",
        "print(df_info)"
      ],
      "metadata": {
        "id": "KQmz8_2vQxBG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7119bfae-1c03-42a3-81ed-baff4803c04e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Combined Information about Columns with Null Values:\n",
            "Empty DataFrame\n",
            "Columns: [Null_Counts, Data_Types]\n",
            "Index: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# label_encoder = LabelEncoder()\n",
        "\n",
        "# nyc_df['store_and_fwd_flag'] = label_encoder.fit_transform(nyc_df['store_and_fwd_flag'])"
      ],
      "metadata": {
        "id": "RUP1nGffRSzK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nyc_df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLViJrQsRzRF",
        "outputId": "4dd839c4-5568-44a1-b151-948326bea169"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 3207040 entries, 0 to 3207039\n",
            "Data columns (total 8 columns):\n",
            " #   Column           Dtype  \n",
            "---  ------           -----  \n",
            " 0   passenger_count  float64\n",
            " 1   trip_distance    float64\n",
            " 2   RatecodeID       float64\n",
            " 3   DOLocationID     int32  \n",
            " 4   payment_type     int64  \n",
            " 5   total_amount     float64\n",
            " 6   Airport_fee      float64\n",
            " 7   trip_duration    float64\n",
            "dtypes: float64(6), int32(1), int64(1)\n",
            "memory usage: 208.0 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nyc_df_float = nyc_df.astype(float)"
      ],
      "metadata": {
        "id": "3Hh-2eroSuZD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# nyc_df_float.corr()"
      ],
      "metadata": {
        "id": "-fiZldiFTnGK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# fig = plt.figure(figsize = (18,18))\n",
        "\n",
        "# fig.add_subplot(1,1,1)\n",
        "# sns.heatmap(nyc_df_float.corr(), annot = True)    # annot = True, to print the values of the Correlation Coefficients.\n",
        "\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "zLpMedqpTnCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# columns_to_drop = ['extra', 'mta_tax','total_amount','VendorID','tolls_amount','tpep_pickup_datetime','tpep_dropoff_datetime','tip_amount','airport_fee','store_and_fwd_flag']\n",
        "# df_taxi_1 = Df_NYC.drop(columns=columns_to_drop)"
      ],
      "metadata": {
        "id": "G4fL7_n3vLiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nyc_df_float.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icKnwyE-UjnY",
        "outputId": "cab7fbc5-f755-4f9c-d5ed-73a8bf1d5f68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3207040, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "\n",
        "# Assuming 'nyc_df' is your DataFrame\n",
        "# Replace this with your actual data or load your dataset\n",
        "\n",
        "# Specify the variables for which to calculate VIF\n",
        "# Exclude variables that might be dependent or cause multicollinearity\n",
        "exclude_vars = ['trip_duration']  # Add other variables to exclude if necessary\n",
        "x_vars = [col for col in nyc_df_float.columns if col not in exclude_vars]\n",
        "\n",
        "# Create a DataFrame containing only the specified x_vars\n",
        "x_data = nyc_df_float[x_vars]\n",
        "\n",
        "# Calculate VIF for each variable\n",
        "vif_data = pd.DataFrame()\n",
        "vif_data[\"Variable\"] = x_vars\n",
        "vif_data[\"VIF\"] = [variance_inflation_factor(x_data.values, i) for i in range(x_data.shape[1])]\n",
        "\n",
        "# Display the VIF values\n",
        "print(vif_data)\n"
      ],
      "metadata": {
        "id": "tQAdaeDBa0w5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "567d901e-a779-4a8c-bea0-65415dcc46ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          Variable       VIF\n",
            "0  passenger_count  3.068424\n",
            "1    trip_distance  1.590433\n",
            "2       RatecodeID  1.051372\n",
            "3     DOLocationID  4.312133\n",
            "4     payment_type  4.063623\n",
            "5     total_amount  3.898675\n",
            "6      Airport_fee  1.743840\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nyc_df_float=nyc_df_float.drop([\"DOLocationID\"],axis=1)"
      ],
      "metadata": {
        "id": "f77un0Bla0t4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "\n",
        "# Assuming 'nyc_df' is your DataFrame\n",
        "# Replace this with your actual data or load your dataset\n",
        "\n",
        "# Specify the variables for which to calculate VIF\n",
        "# Exclude variables that might be dependent or cause multicollinearity\n",
        "exclude_vars = ['trip_duration']  # Add other variables to exclude if necessary\n",
        "x_vars = [col for col in nyc_df_float.columns if col not in exclude_vars]\n",
        "\n",
        "# Create a DataFrame containing only the specified x_vars\n",
        "x_data = nyc_df_float[x_vars]\n",
        "\n",
        "# Calculate VIF for each variable\n",
        "vif_data = pd.DataFrame()\n",
        "vif_data[\"Variable\"] = x_vars\n",
        "vif_data[\"VIF\"] = [variance_inflation_factor(x_data.values, i) for i in range(x_data.shape[1])]\n",
        "\n",
        "# Display the VIF values\n",
        "print(vif_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-Ua67CIa0q2",
        "outputId": "7157e496-0d81-42b1-a0f3-fece4f0fc03f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          Variable       VIF\n",
            "0  passenger_count  2.855366\n",
            "1    trip_distance  1.581950\n",
            "2       RatecodeID  1.051213\n",
            "3     payment_type  2.851939\n",
            "4     total_amount  3.587792\n",
            "5      Airport_fee  1.710177\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# nyc_df_float=nyc_df_float.drop([\"PULocationID\"],axis=1)"
      ],
      "metadata": {
        "id": "WgGnKO0IviRd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "# from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "\n",
        "# # Assuming 'nyc_df' is your DataFrame\n",
        "# # Replace this with your actual data or load your dataset\n",
        "\n",
        "# # Specify the variables for which to calculate VIF\n",
        "# # Exclude variables that might be dependent or cause multicollinearity\n",
        "# exclude_vars = ['trip_duration']  # Add other variables to exclude if necessary\n",
        "# x_vars = [col for col in nyc_df_float.columns if col not in exclude_vars]\n",
        "\n",
        "# # Create a DataFrame containing only the specified x_vars\n",
        "# x_data = nyc_df_float[x_vars]\n",
        "\n",
        "# # Calculate VIF for each variable\n",
        "# vif_data = pd.DataFrame()\n",
        "# vif_data[\"Variable\"] = x_vars\n",
        "# vif_data[\"VIF\"] = [variance_inflation_factor(x_data.values, i) for i in range(x_data.shape[1])]\n",
        "\n",
        "# # Display the VIF values\n",
        "# print(vif_data)\n"
      ],
      "metadata": {
        "id": "evcZ9AUF7U_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Calculate Q1, Q3, and IQR for each column\n",
        "Q1 = nyc_df_float.quantile(0.05)\n",
        "Q3 = nyc_df_float.quantile(0.95)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "# Define lower and upper bounds for each column\n",
        "lower_bound = Q1 - 1.5 * IQR\n",
        "upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "# Identify outliers for each column\n",
        "outliers = (nyc_df_float < lower_bound) | (nyc_df_float > upper_bound)\n",
        "\n",
        "# Optionally, remove outliers from the DataFrame\n",
        "filtered_dataframe1 = nyc_df_float[~outliers.any(axis=1)]\n",
        "\n",
        "# Display information about outliers and filtered DataFrame\n",
        "print(\"Columns with Outliers:\")\n",
        "print(outliers.sum())\n",
        "\n",
        "print(\"\\nOriginal DataFrame Shape:\", nyc_df_float.shape)\n",
        "print(\"Filtered DataFrame Shape:\", filtered_dataframe1.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvVv8UPBa0oq",
        "outputId": "fb9e27c2-4fed-4b01-c905-e426f050c435"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns with Outliers:\n",
            "passenger_count       55\n",
            "trip_distance       1438\n",
            "RatecodeID         49081\n",
            "payment_type       48425\n",
            "total_amount        3012\n",
            "Airport_fee            0\n",
            "trip_duration       5086\n",
            "dtype: int64\n",
            "\n",
            "Original DataFrame Shape: (3207040, 7)\n",
            "Filtered DataFrame Shape: (3106185, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nyc_df_1 = filtered_dataframe1"
      ],
      "metadata": {
        "id": "Gw3olrhOa0l3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=nyc_df_1.drop(columns=[\"trip_duration\"])\n",
        "y=nyc_df_1[\"trip_duration\"]"
      ],
      "metadata": {
        "id": "Sgs8Z6Eca0i6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6gJWWZo_j22",
        "outputId": "3cf5df4d-ab2b-4958-f742-2e0e366b1836"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0          3665.0\n",
              "1          1231.0\n",
              "2          3358.0\n",
              "3            69.0\n",
              "4           475.0\n",
              "            ...  \n",
              "3207035    1170.0\n",
              "3207036     905.0\n",
              "3207037     753.0\n",
              "3207038     372.0\n",
              "3207039     325.0\n",
              "Name: trip_duration, Length: 3106185, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)"
      ],
      "metadata": {
        "id": "hZxG8cmqa0f6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train,X_test,y_train,y_test = train_test_split(X_scaled,y,test_size=0.2,random_state=0)"
      ],
      "metadata": {
        "id": "L6Lji4xZftic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IX7Yq6yHyIq2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Create the Decision Tree Regressor\n",
        "decision_tree = DecisionTreeRegressor()\n",
        "\n",
        "# Train the model on the training set\n",
        "decision_tree.fit(X_train, y_train)\n",
        "\n",
        "y_pred_test_DT = decision_tree.predict(X_test)\n",
        "\n",
        "# Calculate Mean Squared Error\n",
        "mse = mean_squared_error(y_test, y_pred_test_DT)\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "\n",
        "# Calculate Root Mean Squared Error\n",
        "rmse = np.sqrt(mse)\n",
        "print(f\"Root Mean Squared Error: {rmse}\")\n",
        "\n",
        "# Calculate Mean Absolute Error\n",
        "mae = mean_absolute_error(y_test, y_pred_test_DT)\n",
        "print(f\"Mean Absolute Error: {mae}\")\n",
        "\n",
        "# Calculate Root Mean Squared Logarithmic Error\n",
        "rmsle = np.sqrt(np.mean(np.log1p(y_pred_test_DT) - np.log1p(y_test))**2)\n",
        "print(f\"Root Mean Squared Logarithmic Error: {rmsle}\")\n",
        "\n",
        "# Calculate R-squared\n",
        "r2_DT = r2_score(y_test, y_pred_test_DT)\n",
        "print(f\"R-squared: {r2_DT}\")\n",
        "\n",
        "# Calculate Adjusted R-squared\n",
        "n = len(X_test)\n",
        "p = X_test.shape[1]  # number of features\n",
        "adjusted_r2 = 1 - (1 - r2_DT) * (n - 1) / (n - p - 1)\n",
        "print(f\"Adjusted R-squared: {adjusted_r2}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ciDI1RjRvl4a",
        "outputId": "ed222901-eb68-40ac-c865-d39c30a2f05c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 118657.0288013889\n",
            "Root Mean Squared Error: 344.4662955956488\n",
            "Mean Absolute Error: 144.13894900059307\n",
            "Root Mean Squared Logarithmic Error: 0.012348788245836911\n",
            "R-squared: 0.8126244172045232\n",
            "Adjusted R-squared: 0.8126226074826862\n",
            "Mean Absolute Percentage Error: inf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate Mean Absolute Percentage Error\n",
        "mape = np.mean(np.abs((y_test - y_pred_test_DT) / np.maximum(np.abs(y_test), 1))) * 100\n",
        "print(f\"Mean Absolute Percentage Error: {mape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rEZG4K4c5W3f",
        "outputId": "e58dffaf-0279-4b7f-e483-9a6447d92f56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Percentage Error: 33.08449938629339\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j13FToHVyHLl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Create the Linear Regression model\n",
        "linear_reg = LinearRegression()\n",
        "\n",
        "# Train the model on the training set\n",
        "linear_reg.fit(X_train, y_train)\n",
        "\n",
        "y_pred_test_LIR = linear_reg.predict(X_test)\n",
        "\n",
        "# Calculate Mean Squared Error\n",
        "mse = mean_squared_error(y_test, y_pred_test_LIR)\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "\n",
        "# Calculate Root Mean Squared Error\n",
        "rmse = np.sqrt(mse)\n",
        "print(f\"Root Mean Squared Error: {rmse}\")\n",
        "\n",
        "# Calculate Mean Absolute Error\n",
        "mae = mean_absolute_error(y_test, y_pred_test_LIR)\n",
        "print(f\"Mean Absolute Error: {mae}\")\n",
        "\n",
        "# Calculate Root Mean Squared Logarithmic Error\n",
        "rmsle = np.sqrt(np.mean(np.log1p(y_pred_test_LIR) - np.log1p(y_test))**2)\n",
        "print(f\"Root Mean Squared Logarithmic Error: {rmsle}\")\n",
        "\n",
        "# Calculate R-squared\n",
        "r2_LIR = r2_score(y_test, y_pred_test_LIR)\n",
        "print(f\"R-squared: {r2_LIR}\")\n",
        "\n",
        "# Calculate Adjusted R-squared\n",
        "n = len(X_test)\n",
        "p = X_test.shape[1]  # number of features\n",
        "adjusted_r2 = 1 - (1 - r2_LIR) * (n - 1) / (n - p - 1)\n",
        "print(f\"Adjusted R-squared: {adjusted_r2}\")\n",
        "\n",
        "# Calculate Mean Absolute Percentage Error\n",
        "mape = np.mean(np.abs((y_test - y_pred_test_LIR) / np.maximum(np.abs(y_test), 1))) * 100\n",
        "print(f\"Mean Absolute Percentage Error: {mape}\")\n"
      ],
      "metadata": {
        "id": "DHI21DItlY19",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92c626ff-da6e-4ef9-c1b6-d22244704b1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 175456.52309560325\n",
            "Root Mean Squared Error: 418.8753073357312\n",
            "Mean Absolute Error: 260.75593211980635\n",
            "Root Mean Squared Logarithmic Error: 0.1240562971155228\n",
            "R-squared: 0.7229302924369039\n",
            "Adjusted R-squared: 0.7229276164260137\n",
            "Mean Absolute Percentage Error: 97.7234610218689\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZVOI7k5NyGA7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Create the RandomForestRegressor model\n",
        "rf_regressor = RandomForestRegressor(n_estimators=51)\n",
        "rf_regressor.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_rf = rf_regressor.predict(X_test)\n",
        "\n",
        "# Calculate Mean Squared Error\n",
        "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
        "print(f\"Mean Squared Error: {mse_rf}\")\n",
        "\n",
        "# Calculate Root Mean Squared Error\n",
        "rmse_rf = np.sqrt(mse_rf)\n",
        "print(f\"Root Mean Squared Error: {rmse_rf}\")\n",
        "\n",
        "# Calculate Mean Absolute Error\n",
        "mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
        "print(f\"Mean Absolute Error: {mae_rf}\")\n",
        "\n",
        "# Calculate Root Mean Squared Logarithmic Error\n",
        "rmsle_rf = np.sqrt(np.mean(np.log1p(y_pred_rf) - np.log1p(y_test))**2)\n",
        "print(f\"Root Mean Squared Logarithmic Error: {rmsle_rf}\")\n",
        "\n",
        "# Calculate R-squared\n",
        "r2_rf = r2_score(y_test, y_pred_rf)\n",
        "print(f\"R-squared: {r2_rf}\")\n",
        "\n",
        "# Calculate Adjusted R-squared (Not applicable for RandomForestRegressor as it does not involve multiple features)\n",
        "# Adjusted R-squared is more suitable for models with multiple features.\n",
        "\n",
        "# Calculate Mean Absolute Percentage Error\n",
        "mape_rf = np.mean(np.abs((y_test - y_pred_rf) / np.maximum(np.abs(y_test), 1))) * 100\n",
        "print(f\"Mean Absolute Percentage Error: {mape_rf}\")\n",
        "\n",
        "# Optionally, you can also inspect feature importances\n",
        "feature_importances_rf = rf_regressor.feature_importances_\n",
        "print(\"Feature Importances:\")\n",
        "for feature, importance in zip(X.columns, feature_importances_rf):\n",
        "    print(f\"{feature}: {importance}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fm_-8Lgz3bIL",
        "outputId": "c1483a17-9d19-447f-d253-121e68508e25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 86565.37427078202\n",
            "Root Mean Squared Error: 294.21994200050756\n",
            "Mean Absolute Error: 129.1712459514094\n",
            "Root Mean Squared Logarithmic Error: 0.017868801301058477\n",
            "R-squared: 0.8633015033517635\n",
            "Mean Absolute Percentage Error: 32.37314724064272\n",
            "Feature Importances:\n",
            "passenger_count: 0.009467244690288168\n",
            "trip_distance: 0.08734912561545159\n",
            "RatecodeID: 0.011013740133255213\n",
            "payment_type: 0.015121032617461337\n",
            "total_amount: 0.8713331103377925\n",
            "Airport_fee: 0.005715746605751163\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fTtiBsH8xY0K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mean Squared Error: 86565.37427078202\n",
        "\n",
        "Root Mean Squared Error: 294.21994200050756\n",
        "\n",
        "Mean Absolute Error: 129.1712459514094\n",
        "\n",
        "Root Mean Squared Logarithmic Error: 0.017868801301058477\n",
        "\n",
        "R-squared: 0.8633015033517635\n",
        "\n",
        "Mean Absolute Percentage Error: 32.37314724064272\n",
        "\n",
        "Feature Importances:\n",
        "\n",
        "passenger_count: 0.009467244690288168\n",
        "\n",
        "trip_distance: 0.08734912561545159\n",
        "\n",
        "RatecodeID: 0.011013740133255213\n",
        "\n",
        "payment_type: 0.015121032617461337\n",
        "\n",
        "total_amount: 0.8713331103377925\n",
        "\n",
        "Airport_fee: 0.005715746605751163\n",
        "\n",
        "\n",
        "1716PM"
      ],
      "metadata": {
        "id": "Ar2PDz9sCdrV"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V7-x-wZLyEmN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y4K_E7O2yQEI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Create and train the XGBoost regression model\n",
        "xgb_regressor = xgb.XGBRegressor(objective='reg:squarederror', random_state=42,n_estimators=48,)\n",
        "xgb_regressor.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_xgb = xgb_regressor.predict(X_test)\n",
        "\n",
        "# Calculate Mean Squared Error\n",
        "mse_xgb = mean_squared_error(y_test, y_pred_xgb)\n",
        "print(f\"XGBoost Mean Squared Error: {mse_xgb}\")\n",
        "\n",
        "# Calculate Root Mean Squared Error\n",
        "rmse_xgb = np.sqrt(mse_xgb)\n",
        "print(f\"XGBoost Root Mean Squared Error: {rmse_xgb}\")\n",
        "\n",
        "# Calculate Mean Absolute Error\n",
        "mae_xgb = mean_absolute_error(y_test, y_pred_xgb)\n",
        "print(f\"XGBoost Mean Absolute Error: {mae_xgb}\")\n",
        "\n",
        "# Calculate Root Mean Squared Logarithmic Error\n",
        "rmsle_xgb = np.sqrt(np.mean(np.log1p(y_pred_xgb) - np.log1p(y_test))**2)\n",
        "print(f\"XGBoost Root Mean Squared Logarithmic Error: {rmsle_xgb}\")\n",
        "\n",
        "# Calculate R-squared\n",
        "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
        "print(f\"XGBoost R-squared: {r2_xgb}\")\n",
        "\n",
        "# Calculate Adjusted R-squared (Not applicable for XGBoostRegressor as it does not involve multiple features)\n",
        "# Adjusted R-squared is more suitable for models with multiple features.\n",
        "\n",
        "# Calculate Mean Absolute Percentage Error\n",
        "mape_xgb = np.mean(np.abs((y_test - y_pred_xgb) / np.maximum(np.abs(y_test), 1))) * 100\n",
        "print(f\"XGBoost Mean Absolute Percentage Error: {mape_xgb}\")\n"
      ],
      "metadata": {
        "id": "IzlDiOZP29zP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "716be301-33d4-4595-cef6-40f1a8aa99b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost Mean Squared Error: 86954.20596316845\n",
            "XGBoost Root Mean Squared Error: 294.879985694466\n",
            "XGBoost Mean Absolute Error: 158.23909121324917\n",
            "XGBoost Root Mean Squared Logarithmic Error: 0.03775203526798858\n",
            "XGBoost R-squared: 0.8626874852383299\n",
            "XGBoost Mean Absolute Percentage Error: 41.12376395367203\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hN3JInQzy8OV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Create and train the LightGBM regression model\n",
        "lgb_regressor = lgb.LGBMRegressor()\n",
        "lgb_regressor.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_lgb = lgb_regressor.predict(X_test)\n",
        "\n",
        "# Calculate Mean Squared Error\n",
        "mse_lgb = mean_squared_error(y_test, y_pred_lgb)\n",
        "print(f\"LightGBM Mean Squared Error: {mse_lgb}\")\n",
        "\n",
        "# Calculate Root Mean Squared Error\n",
        "rmse_lgb = np.sqrt(mse_lgb)\n",
        "print(f\"LightGBM Root Mean Squared Error: {rmse_lgb}\")\n",
        "\n",
        "# Calculate Mean Absolute Error\n",
        "mae_lgb = mean_absolute_error(y_test, y_pred_lgb)\n",
        "print(f\"LightGBM Mean Absolute Error: {mae_lgb}\")\n",
        "\n",
        "# Calculate Root Mean Squared Logarithmic Error\n",
        "rmsle_lgb = np.sqrt(np.mean(np.log1p(y_pred_lgb) - np.log1p(y_test))**2)\n",
        "print(f\"LightGBM Root Mean Squared Logarithmic Error: {rmsle_lgb}\")\n",
        "\n",
        "# Calculate R-squared\n",
        "r2_lgb = r2_score(y_test, y_pred_lgb)\n",
        "print(f\"LightGBM R-squared: {r2_lgb}\")\n",
        "\n",
        "# Calculate Adjusted R-squared (Not applicable for LightGBMRegressor as it does not involve multiple features)\n",
        "# Adjusted R-squared is more suitable for models with multiple features.\n",
        "\n",
        "# Calculate Mean Absolute Percentage Error\n",
        "mape_lgb = np.mean(np.abs((y_test - y_pred_lgb) / np.maximum(np.abs(y_test), 1))) * 100\n",
        "print(f\"LightGBM Mean Absolute Percentage Error: {mape_lgb}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KljA0MeABukF",
        "outputId": "84439d35-5e41-4b64-f920-86c633913e91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.306168 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 724\n",
            "[LightGBM] [Info] Number of data points in the train set: 2484948, number of used features: 7\n",
            "[LightGBM] [Info] Start training from score 1010.336710\n",
            "LightGBM Mean Squared Error: 84924.74319971872\n",
            "LightGBM Root Mean Squared Error: 291.4185018143473\n",
            "LightGBM Mean Absolute Error: 155.69829574498954\n",
            "LightGBM Root Mean Squared Logarithmic Error: 0.036410406003747633\n",
            "LightGBM R-squared: 0.865892282896795\n",
            "LightGBM Mean Absolute Percentage Error: 41.00610899489028\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WqfxKI5Sy9YU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eoNjiCu6zflU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import catboost\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Create and train the CatBoost regression model\n",
        "catboost_regressor = catboost.CatBoostRegressor(random_state=42)\n",
        "catboost_regressor.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_catboost = catboost_regressor.predict(X_test)\n",
        "\n",
        "# Calculate Mean Squared Error\n",
        "mse_catboost = mean_squared_error(y_test, y_pred_catboost)\n",
        "print(f\"CatBoost Mean Squared Error: {mse_catboost}\")\n",
        "\n",
        "# Calculate Root Mean Squared Error\n",
        "rmse_catboost = np.sqrt(mse_catboost)\n",
        "print(f\"CatBoost Root Mean Squared Error: {rmse_catboost}\")\n",
        "\n",
        "# Calculate Mean Absolute Error\n",
        "mae_catboost = mean_absolute_error(y_test, y_pred_catboost)\n",
        "print(f\"CatBoost Mean Absolute Error: {mae_catboost}\")\n",
        "\n",
        "# Calculate Root Mean Squared Logarithmic Error\n",
        "rmsle_catboost = np.sqrt(np.mean(np.log1p(y_pred_catboost) - np.log1p(y_test))**2)\n",
        "print(f\"CatBoost Root Mean Squared Logarithmic Error: {rmsle_catboost}\")\n",
        "\n",
        "# Calculate R-squared\n",
        "r2_catboost = r2_score(y_test, y_pred_catboost)\n",
        "print(f\"CatBoost R-squared: {r2_catboost}\")\n",
        "\n",
        "# Calculate Adjusted R-squared (Not applicable for CatBoostRegressor as it does not involve multiple features)\n",
        "# Adjusted R-squared is more suitable for models with multiple features.\n",
        "\n",
        "# Calculate Mean Absolute Percentage Error\n",
        "mape_catboost = np.mean(np.abs((y_test - y_pred_catboost) / np.maximum(np.abs(y_test), 1))) * 100\n",
        "print(f\"CatBoost Mean Absolute Percentage Error: {mape_catboost}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TeVHrwc5zfgj",
        "outputId": "912c84f5-7c20-4b81-c958-078db4b04cae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning rate set to 0.140812\n",
            "0:\tlearn: 712.2689043\ttotal: 570ms\tremaining: 9m 29s\n",
            "1:\tlearn: 642.2600850\ttotal: 908ms\tremaining: 7m 32s\n",
            "2:\tlearn: 583.1126294\ttotal: 1.24s\tremaining: 6m 52s\n",
            "3:\tlearn: 534.7831836\ttotal: 1.55s\tremaining: 6m 26s\n",
            "4:\tlearn: 494.9156031\ttotal: 1.88s\tremaining: 6m 14s\n",
            "5:\tlearn: 462.2799199\ttotal: 2.2s\tremaining: 6m 5s\n",
            "6:\tlearn: 436.2326476\ttotal: 2.53s\tremaining: 5m 58s\n",
            "7:\tlearn: 415.5367038\ttotal: 2.84s\tremaining: 5m 52s\n",
            "8:\tlearn: 399.3601349\ttotal: 3.17s\tremaining: 5m 48s\n",
            "9:\tlearn: 385.7551818\ttotal: 3.47s\tremaining: 5m 43s\n",
            "10:\tlearn: 375.1642939\ttotal: 3.78s\tremaining: 5m 39s\n",
            "11:\tlearn: 366.3801030\ttotal: 4.1s\tremaining: 5m 37s\n",
            "12:\tlearn: 359.4073774\ttotal: 4.41s\tremaining: 5m 34s\n",
            "13:\tlearn: 352.8485011\ttotal: 4.72s\tremaining: 5m 32s\n",
            "14:\tlearn: 348.2313609\ttotal: 5.03s\tremaining: 5m 30s\n",
            "15:\tlearn: 344.1249682\ttotal: 5.33s\tremaining: 5m 27s\n",
            "16:\tlearn: 340.3236962\ttotal: 5.63s\tremaining: 5m 25s\n",
            "17:\tlearn: 337.1903056\ttotal: 5.94s\tremaining: 5m 23s\n",
            "18:\tlearn: 334.7704023\ttotal: 6.26s\tremaining: 5m 23s\n",
            "19:\tlearn: 332.5557106\ttotal: 6.58s\tremaining: 5m 22s\n",
            "20:\tlearn: 330.8324668\ttotal: 6.87s\tremaining: 5m 20s\n",
            "21:\tlearn: 329.0765730\ttotal: 7.19s\tremaining: 5m 19s\n",
            "22:\tlearn: 327.7145560\ttotal: 7.47s\tremaining: 5m 17s\n",
            "23:\tlearn: 326.3319188\ttotal: 7.81s\tremaining: 5m 17s\n",
            "24:\tlearn: 325.4407117\ttotal: 8.28s\tremaining: 5m 23s\n",
            "25:\tlearn: 324.3280396\ttotal: 8.86s\tremaining: 5m 31s\n",
            "26:\tlearn: 323.3817035\ttotal: 9.39s\tremaining: 5m 38s\n",
            "27:\tlearn: 322.5448339\ttotal: 9.92s\tremaining: 5m 44s\n",
            "28:\tlearn: 321.7752624\ttotal: 10.5s\tremaining: 5m 50s\n",
            "29:\tlearn: 320.8808548\ttotal: 11s\tremaining: 5m 54s\n",
            "30:\tlearn: 320.0035936\ttotal: 11.5s\tremaining: 5m 59s\n",
            "31:\tlearn: 319.4688884\ttotal: 11.8s\tremaining: 5m 56s\n",
            "32:\tlearn: 319.0741325\ttotal: 12.1s\tremaining: 5m 53s\n",
            "33:\tlearn: 318.4177259\ttotal: 12.4s\tremaining: 5m 53s\n",
            "34:\tlearn: 317.9979778\ttotal: 12.7s\tremaining: 5m 50s\n",
            "35:\tlearn: 317.0059343\ttotal: 13s\tremaining: 5m 49s\n",
            "36:\tlearn: 316.3872697\ttotal: 13.3s\tremaining: 5m 46s\n",
            "37:\tlearn: 315.9877112\ttotal: 13.6s\tremaining: 5m 45s\n",
            "38:\tlearn: 315.3290285\ttotal: 14s\tremaining: 5m 43s\n",
            "39:\tlearn: 314.9659566\ttotal: 14.3s\tremaining: 5m 42s\n",
            "40:\tlearn: 314.4581362\ttotal: 14.6s\tremaining: 5m 40s\n",
            "41:\tlearn: 313.6774446\ttotal: 14.9s\tremaining: 5m 39s\n",
            "42:\tlearn: 313.1822180\ttotal: 15.2s\tremaining: 5m 38s\n",
            "43:\tlearn: 312.9444226\ttotal: 15.5s\tremaining: 5m 37s\n",
            "44:\tlearn: 312.3703007\ttotal: 15.8s\tremaining: 5m 35s\n",
            "45:\tlearn: 311.8301823\ttotal: 16.1s\tremaining: 5m 34s\n",
            "46:\tlearn: 311.6075867\ttotal: 16.4s\tremaining: 5m 33s\n",
            "47:\tlearn: 311.2784583\ttotal: 16.7s\tremaining: 5m 32s\n",
            "48:\tlearn: 310.8945826\ttotal: 17s\tremaining: 5m 30s\n",
            "49:\tlearn: 310.5595167\ttotal: 17.3s\tremaining: 5m 29s\n",
            "50:\tlearn: 310.3570731\ttotal: 17.7s\tremaining: 5m 28s\n",
            "51:\tlearn: 309.6303620\ttotal: 18s\tremaining: 5m 27s\n",
            "52:\tlearn: 309.2463223\ttotal: 18.3s\tremaining: 5m 26s\n",
            "53:\tlearn: 308.9597727\ttotal: 18.6s\tremaining: 5m 25s\n",
            "54:\tlearn: 308.5327338\ttotal: 18.9s\tremaining: 5m 24s\n",
            "55:\tlearn: 308.3053715\ttotal: 19.2s\tremaining: 5m 23s\n",
            "56:\tlearn: 308.1083251\ttotal: 19.5s\tremaining: 5m 22s\n",
            "57:\tlearn: 307.6423257\ttotal: 19.8s\tremaining: 5m 21s\n",
            "58:\tlearn: 307.4128871\ttotal: 20.1s\tremaining: 5m 20s\n",
            "59:\tlearn: 307.1480134\ttotal: 20.4s\tremaining: 5m 18s\n",
            "60:\tlearn: 306.8713863\ttotal: 20.6s\tremaining: 5m 17s\n",
            "61:\tlearn: 306.7206787\ttotal: 20.9s\tremaining: 5m 16s\n",
            "62:\tlearn: 306.4368228\ttotal: 21.2s\tremaining: 5m 15s\n",
            "63:\tlearn: 306.0591284\ttotal: 21.5s\tremaining: 5m 15s\n",
            "64:\tlearn: 305.9275778\ttotal: 22.1s\tremaining: 5m 17s\n",
            "65:\tlearn: 305.7340768\ttotal: 22.5s\tremaining: 5m 18s\n",
            "66:\tlearn: 305.6240407\ttotal: 23.1s\tremaining: 5m 21s\n",
            "67:\tlearn: 305.5049342\ttotal: 23.6s\tremaining: 5m 23s\n",
            "68:\tlearn: 305.3518361\ttotal: 24.2s\tremaining: 5m 26s\n",
            "69:\tlearn: 305.0362262\ttotal: 24.7s\tremaining: 5m 28s\n",
            "70:\tlearn: 304.8467504\ttotal: 25.2s\tremaining: 5m 30s\n",
            "71:\tlearn: 304.6239213\ttotal: 25.6s\tremaining: 5m 29s\n",
            "72:\tlearn: 304.5067399\ttotal: 25.9s\tremaining: 5m 28s\n",
            "73:\tlearn: 304.2113408\ttotal: 26.1s\tremaining: 5m 27s\n",
            "74:\tlearn: 303.9244038\ttotal: 26.4s\tremaining: 5m 26s\n",
            "75:\tlearn: 303.8301109\ttotal: 26.8s\tremaining: 5m 25s\n",
            "76:\tlearn: 303.5953552\ttotal: 27.1s\tremaining: 5m 24s\n",
            "77:\tlearn: 303.4743717\ttotal: 27.3s\tremaining: 5m 23s\n",
            "78:\tlearn: 303.2335018\ttotal: 27.6s\tremaining: 5m 22s\n",
            "79:\tlearn: 303.0640971\ttotal: 27.9s\tremaining: 5m 21s\n",
            "80:\tlearn: 302.8675584\ttotal: 28.2s\tremaining: 5m 20s\n",
            "81:\tlearn: 302.7898739\ttotal: 28.5s\tremaining: 5m 19s\n",
            "82:\tlearn: 302.5846184\ttotal: 28.9s\tremaining: 5m 18s\n",
            "83:\tlearn: 302.5287800\ttotal: 29.2s\tremaining: 5m 17s\n",
            "84:\tlearn: 302.3875552\ttotal: 29.4s\tremaining: 5m 17s\n",
            "85:\tlearn: 302.2262287\ttotal: 29.7s\tremaining: 5m 15s\n",
            "86:\tlearn: 302.1463665\ttotal: 30.1s\tremaining: 5m 15s\n",
            "87:\tlearn: 301.8948293\ttotal: 30.4s\tremaining: 5m 14s\n",
            "88:\tlearn: 301.7435456\ttotal: 30.6s\tremaining: 5m 13s\n",
            "89:\tlearn: 301.6578958\ttotal: 30.9s\tremaining: 5m 12s\n",
            "90:\tlearn: 301.5480784\ttotal: 31.2s\tremaining: 5m 12s\n",
            "91:\tlearn: 301.3425174\ttotal: 31.6s\tremaining: 5m 11s\n",
            "92:\tlearn: 301.1590389\ttotal: 31.9s\tremaining: 5m 10s\n",
            "93:\tlearn: 301.0866148\ttotal: 32.2s\tremaining: 5m 10s\n",
            "94:\tlearn: 300.9357114\ttotal: 32.5s\tremaining: 5m 9s\n",
            "95:\tlearn: 300.8262363\ttotal: 32.8s\tremaining: 5m 8s\n",
            "96:\tlearn: 300.7070415\ttotal: 33.1s\tremaining: 5m 8s\n",
            "97:\tlearn: 300.6213321\ttotal: 33.4s\tremaining: 5m 7s\n",
            "98:\tlearn: 300.4706933\ttotal: 33.7s\tremaining: 5m 6s\n",
            "99:\tlearn: 300.3178099\ttotal: 34s\tremaining: 5m 5s\n",
            "100:\tlearn: 300.1718986\ttotal: 34.3s\tremaining: 5m 5s\n",
            "101:\tlearn: 300.0941584\ttotal: 34.6s\tremaining: 5m 4s\n",
            "102:\tlearn: 299.9910083\ttotal: 34.9s\tremaining: 5m 4s\n",
            "103:\tlearn: 299.9068441\ttotal: 35.2s\tremaining: 5m 3s\n",
            "104:\tlearn: 299.7005089\ttotal: 35.6s\tremaining: 5m 3s\n",
            "105:\tlearn: 299.5849903\ttotal: 36.2s\tremaining: 5m 5s\n",
            "106:\tlearn: 299.4639910\ttotal: 36.7s\tremaining: 5m 6s\n",
            "107:\tlearn: 299.3724735\ttotal: 37.3s\tremaining: 5m 7s\n",
            "108:\tlearn: 299.2742282\ttotal: 37.9s\tremaining: 5m 9s\n",
            "109:\tlearn: 299.2188453\ttotal: 38.4s\tremaining: 5m 10s\n",
            "110:\tlearn: 299.0570638\ttotal: 38.9s\tremaining: 5m 11s\n",
            "111:\tlearn: 298.8657352\ttotal: 39.3s\tremaining: 5m 11s\n",
            "112:\tlearn: 298.7355897\ttotal: 39.6s\tremaining: 5m 10s\n",
            "113:\tlearn: 298.6731327\ttotal: 39.9s\tremaining: 5m 10s\n",
            "114:\tlearn: 298.5614032\ttotal: 40.2s\tremaining: 5m 9s\n",
            "115:\tlearn: 298.4904204\ttotal: 40.5s\tremaining: 5m 8s\n",
            "116:\tlearn: 298.4492911\ttotal: 40.8s\tremaining: 5m 7s\n",
            "117:\tlearn: 298.3447903\ttotal: 41.1s\tremaining: 5m 6s\n",
            "118:\tlearn: 298.2166886\ttotal: 41.4s\tremaining: 5m 6s\n",
            "119:\tlearn: 298.0528196\ttotal: 41.7s\tremaining: 5m 5s\n",
            "120:\tlearn: 297.9097631\ttotal: 42s\tremaining: 5m 5s\n",
            "121:\tlearn: 297.8374778\ttotal: 42.3s\tremaining: 5m 4s\n",
            "122:\tlearn: 297.7323193\ttotal: 42.7s\tremaining: 5m 4s\n",
            "123:\tlearn: 297.6299066\ttotal: 42.9s\tremaining: 5m 3s\n",
            "124:\tlearn: 297.5864408\ttotal: 43.3s\tremaining: 5m 2s\n",
            "125:\tlearn: 297.5238911\ttotal: 43.6s\tremaining: 5m 2s\n",
            "126:\tlearn: 297.4512725\ttotal: 43.9s\tremaining: 5m 1s\n",
            "127:\tlearn: 297.3422561\ttotal: 44.2s\tremaining: 5m\n",
            "128:\tlearn: 297.2557204\ttotal: 44.4s\tremaining: 5m\n",
            "129:\tlearn: 297.1366248\ttotal: 44.8s\tremaining: 4m 59s\n",
            "130:\tlearn: 297.0734469\ttotal: 45s\tremaining: 4m 58s\n",
            "131:\tlearn: 296.9960405\ttotal: 45.4s\tremaining: 4m 58s\n",
            "132:\tlearn: 296.8856090\ttotal: 45.7s\tremaining: 4m 58s\n",
            "133:\tlearn: 296.8345611\ttotal: 46s\tremaining: 4m 57s\n",
            "134:\tlearn: 296.7862609\ttotal: 46.3s\tremaining: 4m 56s\n",
            "135:\tlearn: 296.7170733\ttotal: 46.6s\tremaining: 4m 56s\n",
            "136:\tlearn: 296.6487640\ttotal: 46.9s\tremaining: 4m 55s\n",
            "137:\tlearn: 296.5148796\ttotal: 47.3s\tremaining: 4m 55s\n",
            "138:\tlearn: 296.4490489\ttotal: 47.6s\tremaining: 4m 54s\n",
            "139:\tlearn: 296.3944797\ttotal: 47.9s\tremaining: 4m 54s\n",
            "140:\tlearn: 296.3369196\ttotal: 48.2s\tremaining: 4m 53s\n",
            "141:\tlearn: 296.2897062\ttotal: 48.5s\tremaining: 4m 52s\n",
            "142:\tlearn: 296.2396069\ttotal: 48.8s\tremaining: 4m 52s\n",
            "143:\tlearn: 296.1713918\ttotal: 49.2s\tremaining: 4m 52s\n",
            "144:\tlearn: 296.1170728\ttotal: 49.8s\tremaining: 4m 53s\n",
            "145:\tlearn: 296.0589346\ttotal: 50.3s\tremaining: 4m 54s\n",
            "146:\tlearn: 296.0204382\ttotal: 50.8s\tremaining: 4m 54s\n",
            "147:\tlearn: 295.9846768\ttotal: 51.4s\tremaining: 4m 55s\n",
            "148:\tlearn: 295.8849841\ttotal: 51.9s\tremaining: 4m 56s\n",
            "149:\tlearn: 295.8175831\ttotal: 52.4s\tremaining: 4m 57s\n",
            "150:\tlearn: 295.7858309\ttotal: 52.9s\tremaining: 4m 57s\n",
            "151:\tlearn: 295.7116980\ttotal: 53.2s\tremaining: 4m 56s\n",
            "152:\tlearn: 295.6198791\ttotal: 53.5s\tremaining: 4m 56s\n",
            "153:\tlearn: 295.5749350\ttotal: 53.8s\tremaining: 4m 55s\n",
            "154:\tlearn: 295.4656433\ttotal: 54.1s\tremaining: 4m 55s\n",
            "155:\tlearn: 295.3776619\ttotal: 54.4s\tremaining: 4m 54s\n",
            "156:\tlearn: 295.3193315\ttotal: 54.7s\tremaining: 4m 53s\n",
            "157:\tlearn: 295.2199465\ttotal: 55s\tremaining: 4m 53s\n",
            "158:\tlearn: 295.1552260\ttotal: 55.3s\tremaining: 4m 52s\n",
            "159:\tlearn: 295.0221577\ttotal: 55.6s\tremaining: 4m 52s\n",
            "160:\tlearn: 294.8940584\ttotal: 55.9s\tremaining: 4m 51s\n",
            "161:\tlearn: 294.8147202\ttotal: 56.2s\tremaining: 4m 50s\n",
            "162:\tlearn: 294.7130614\ttotal: 56.6s\tremaining: 4m 50s\n",
            "163:\tlearn: 294.6033062\ttotal: 56.9s\tremaining: 4m 49s\n",
            "164:\tlearn: 294.5234304\ttotal: 57.2s\tremaining: 4m 49s\n",
            "165:\tlearn: 294.4667608\ttotal: 57.5s\tremaining: 4m 48s\n",
            "166:\tlearn: 294.3866740\ttotal: 57.8s\tremaining: 4m 48s\n",
            "167:\tlearn: 294.2654571\ttotal: 58.1s\tremaining: 4m 47s\n",
            "168:\tlearn: 294.2245875\ttotal: 58.4s\tremaining: 4m 47s\n",
            "169:\tlearn: 294.1928122\ttotal: 58.7s\tremaining: 4m 46s\n",
            "170:\tlearn: 294.1530567\ttotal: 59s\tremaining: 4m 45s\n",
            "171:\tlearn: 294.1012712\ttotal: 59.3s\tremaining: 4m 45s\n",
            "172:\tlearn: 294.0549632\ttotal: 59.6s\tremaining: 4m 44s\n",
            "173:\tlearn: 293.9906476\ttotal: 59.9s\tremaining: 4m 44s\n",
            "174:\tlearn: 293.9586657\ttotal: 1m\tremaining: 4m 43s\n",
            "175:\tlearn: 293.9156956\ttotal: 1m\tremaining: 4m 43s\n",
            "176:\tlearn: 293.8728503\ttotal: 1m\tremaining: 4m 42s\n",
            "177:\tlearn: 293.8117062\ttotal: 1m 1s\tremaining: 4m 42s\n",
            "178:\tlearn: 293.7679389\ttotal: 1m 1s\tremaining: 4m 41s\n",
            "179:\tlearn: 293.7216111\ttotal: 1m 1s\tremaining: 4m 41s\n",
            "180:\tlearn: 293.6858073\ttotal: 1m 2s\tremaining: 4m 40s\n",
            "181:\tlearn: 293.6403108\ttotal: 1m 2s\tremaining: 4m 40s\n",
            "182:\tlearn: 293.6095941\ttotal: 1m 2s\tremaining: 4m 39s\n",
            "183:\tlearn: 293.5642428\ttotal: 1m 3s\tremaining: 4m 39s\n",
            "184:\tlearn: 293.5242904\ttotal: 1m 3s\tremaining: 4m 40s\n",
            "185:\tlearn: 293.4988630\ttotal: 1m 4s\tremaining: 4m 40s\n",
            "186:\tlearn: 293.4346954\ttotal: 1m 4s\tremaining: 4m 41s\n",
            "187:\tlearn: 293.3899660\ttotal: 1m 5s\tremaining: 4m 42s\n",
            "188:\tlearn: 293.3655397\ttotal: 1m 5s\tremaining: 4m 42s\n",
            "189:\tlearn: 293.3234634\ttotal: 1m 6s\tremaining: 4m 42s\n",
            "190:\tlearn: 293.2905268\ttotal: 1m 6s\tremaining: 4m 42s\n",
            "191:\tlearn: 293.2646962\ttotal: 1m 7s\tremaining: 4m 42s\n",
            "192:\tlearn: 293.2187497\ttotal: 1m 7s\tremaining: 4m 41s\n",
            "193:\tlearn: 293.1771394\ttotal: 1m 7s\tremaining: 4m 41s\n",
            "194:\tlearn: 293.1412146\ttotal: 1m 8s\tremaining: 4m 40s\n",
            "195:\tlearn: 293.0745389\ttotal: 1m 8s\tremaining: 4m 40s\n",
            "196:\tlearn: 293.0409010\ttotal: 1m 8s\tremaining: 4m 39s\n",
            "197:\tlearn: 292.9378547\ttotal: 1m 8s\tremaining: 4m 39s\n",
            "198:\tlearn: 292.8978074\ttotal: 1m 9s\tremaining: 4m 38s\n",
            "199:\tlearn: 292.8411208\ttotal: 1m 9s\tremaining: 4m 38s\n",
            "200:\tlearn: 292.7887829\ttotal: 1m 9s\tremaining: 4m 37s\n",
            "201:\tlearn: 292.7237968\ttotal: 1m 10s\tremaining: 4m 37s\n",
            "202:\tlearn: 292.6974982\ttotal: 1m 10s\tremaining: 4m 36s\n",
            "203:\tlearn: 292.6557524\ttotal: 1m 10s\tremaining: 4m 36s\n",
            "204:\tlearn: 292.6311705\ttotal: 1m 11s\tremaining: 4m 35s\n",
            "205:\tlearn: 292.5791533\ttotal: 1m 11s\tremaining: 4m 35s\n",
            "206:\tlearn: 292.5319991\ttotal: 1m 11s\tremaining: 4m 34s\n",
            "207:\tlearn: 292.5019034\ttotal: 1m 12s\tremaining: 4m 34s\n",
            "208:\tlearn: 292.4476639\ttotal: 1m 12s\tremaining: 4m 33s\n",
            "209:\tlearn: 292.3918942\ttotal: 1m 12s\tremaining: 4m 33s\n",
            "210:\tlearn: 292.3280411\ttotal: 1m 12s\tremaining: 4m 32s\n",
            "211:\tlearn: 292.2762915\ttotal: 1m 13s\tremaining: 4m 32s\n",
            "212:\tlearn: 292.2284568\ttotal: 1m 14s\tremaining: 4m 33s\n",
            "213:\tlearn: 292.1989442\ttotal: 1m 14s\tremaining: 4m 33s\n",
            "214:\tlearn: 292.1675232\ttotal: 1m 14s\tremaining: 4m 32s\n",
            "215:\tlearn: 292.1423628\ttotal: 1m 15s\tremaining: 4m 32s\n",
            "216:\tlearn: 292.1071064\ttotal: 1m 15s\tremaining: 4m 31s\n",
            "217:\tlearn: 292.0772370\ttotal: 1m 15s\tremaining: 4m 31s\n",
            "218:\tlearn: 292.0543262\ttotal: 1m 16s\tremaining: 4m 31s\n",
            "219:\tlearn: 292.0040083\ttotal: 1m 16s\tremaining: 4m 30s\n",
            "220:\tlearn: 291.9703344\ttotal: 1m 16s\tremaining: 4m 30s\n",
            "221:\tlearn: 291.9448757\ttotal: 1m 17s\tremaining: 4m 30s\n",
            "222:\tlearn: 291.9083452\ttotal: 1m 17s\tremaining: 4m 31s\n",
            "223:\tlearn: 291.8418581\ttotal: 1m 18s\tremaining: 4m 31s\n",
            "224:\tlearn: 291.8267119\ttotal: 1m 18s\tremaining: 4m 31s\n",
            "225:\tlearn: 291.7757854\ttotal: 1m 19s\tremaining: 4m 32s\n",
            "226:\tlearn: 291.7476179\ttotal: 1m 20s\tremaining: 4m 32s\n",
            "227:\tlearn: 291.6746433\ttotal: 1m 20s\tremaining: 4m 32s\n",
            "228:\tlearn: 291.6256056\ttotal: 1m 20s\tremaining: 4m 31s\n",
            "229:\tlearn: 291.5953772\ttotal: 1m 21s\tremaining: 4m 31s\n",
            "230:\tlearn: 291.5691686\ttotal: 1m 21s\tremaining: 4m 31s\n",
            "231:\tlearn: 291.5346638\ttotal: 1m 21s\tremaining: 4m 30s\n",
            "232:\tlearn: 291.4690176\ttotal: 1m 22s\tremaining: 4m 30s\n",
            "233:\tlearn: 291.4424107\ttotal: 1m 22s\tremaining: 4m 29s\n",
            "234:\tlearn: 291.4068466\ttotal: 1m 22s\tremaining: 4m 29s\n",
            "235:\tlearn: 291.3374946\ttotal: 1m 23s\tremaining: 4m 28s\n",
            "236:\tlearn: 291.2626553\ttotal: 1m 23s\tremaining: 4m 28s\n",
            "237:\tlearn: 291.2169573\ttotal: 1m 23s\tremaining: 4m 28s\n",
            "238:\tlearn: 291.1872798\ttotal: 1m 23s\tremaining: 4m 27s\n",
            "239:\tlearn: 291.1623193\ttotal: 1m 24s\tremaining: 4m 27s\n",
            "240:\tlearn: 291.1232943\ttotal: 1m 24s\tremaining: 4m 26s\n",
            "241:\tlearn: 291.0898464\ttotal: 1m 24s\tremaining: 4m 25s\n",
            "242:\tlearn: 291.0338884\ttotal: 1m 25s\tremaining: 4m 25s\n",
            "243:\tlearn: 290.9755123\ttotal: 1m 25s\tremaining: 4m 25s\n",
            "244:\tlearn: 290.9521926\ttotal: 1m 25s\tremaining: 4m 24s\n",
            "245:\tlearn: 290.9207436\ttotal: 1m 26s\tremaining: 4m 24s\n",
            "246:\tlearn: 290.8820911\ttotal: 1m 26s\tremaining: 4m 23s\n",
            "247:\tlearn: 290.8526613\ttotal: 1m 26s\tremaining: 4m 23s\n",
            "248:\tlearn: 290.8252704\ttotal: 1m 27s\tremaining: 4m 22s\n",
            "249:\tlearn: 290.8004685\ttotal: 1m 27s\tremaining: 4m 22s\n",
            "250:\tlearn: 290.7568132\ttotal: 1m 27s\tremaining: 4m 21s\n",
            "251:\tlearn: 290.7315873\ttotal: 1m 27s\tremaining: 4m 21s\n",
            "252:\tlearn: 290.7026236\ttotal: 1m 28s\tremaining: 4m 20s\n",
            "253:\tlearn: 290.6667092\ttotal: 1m 28s\tremaining: 4m 20s\n",
            "254:\tlearn: 290.6406608\ttotal: 1m 28s\tremaining: 4m 19s\n",
            "255:\tlearn: 290.5883789\ttotal: 1m 29s\tremaining: 4m 19s\n",
            "256:\tlearn: 290.5528082\ttotal: 1m 29s\tremaining: 4m 18s\n",
            "257:\tlearn: 290.5195890\ttotal: 1m 29s\tremaining: 4m 18s\n",
            "258:\tlearn: 290.4962788\ttotal: 1m 30s\tremaining: 4m 17s\n",
            "259:\tlearn: 290.4740328\ttotal: 1m 30s\tremaining: 4m 17s\n",
            "260:\tlearn: 290.4506283\ttotal: 1m 30s\tremaining: 4m 17s\n",
            "261:\tlearn: 290.4140678\ttotal: 1m 31s\tremaining: 4m 17s\n",
            "262:\tlearn: 290.3882007\ttotal: 1m 31s\tremaining: 4m 17s\n",
            "263:\tlearn: 290.3660482\ttotal: 1m 32s\tremaining: 4m 17s\n",
            "264:\tlearn: 290.3461320\ttotal: 1m 32s\tremaining: 4m 17s\n",
            "265:\tlearn: 290.3128776\ttotal: 1m 33s\tremaining: 4m 18s\n",
            "266:\tlearn: 290.2922206\ttotal: 1m 34s\tremaining: 4m 18s\n",
            "267:\tlearn: 290.2274841\ttotal: 1m 34s\tremaining: 4m 17s\n",
            "268:\tlearn: 290.2019692\ttotal: 1m 34s\tremaining: 4m 17s\n",
            "269:\tlearn: 290.1639758\ttotal: 1m 34s\tremaining: 4m 16s\n",
            "270:\tlearn: 290.1420225\ttotal: 1m 35s\tremaining: 4m 16s\n",
            "271:\tlearn: 290.0972420\ttotal: 1m 35s\tremaining: 4m 15s\n",
            "272:\tlearn: 290.0796344\ttotal: 1m 35s\tremaining: 4m 15s\n",
            "273:\tlearn: 290.0512099\ttotal: 1m 36s\tremaining: 4m 14s\n",
            "274:\tlearn: 290.0365777\ttotal: 1m 36s\tremaining: 4m 14s\n",
            "275:\tlearn: 290.0018115\ttotal: 1m 36s\tremaining: 4m 13s\n",
            "276:\tlearn: 289.9475334\ttotal: 1m 37s\tremaining: 4m 13s\n",
            "277:\tlearn: 289.9245811\ttotal: 1m 37s\tremaining: 4m 12s\n",
            "278:\tlearn: 289.9047156\ttotal: 1m 37s\tremaining: 4m 12s\n",
            "279:\tlearn: 289.8844567\ttotal: 1m 37s\tremaining: 4m 11s\n",
            "280:\tlearn: 289.8558586\ttotal: 1m 38s\tremaining: 4m 11s\n",
            "281:\tlearn: 289.8205507\ttotal: 1m 38s\tremaining: 4m 10s\n",
            "282:\tlearn: 289.7729328\ttotal: 1m 38s\tremaining: 4m 10s\n",
            "283:\tlearn: 289.7556650\ttotal: 1m 39s\tremaining: 4m 9s\n",
            "284:\tlearn: 289.7304589\ttotal: 1m 39s\tremaining: 4m 9s\n",
            "285:\tlearn: 289.6858311\ttotal: 1m 39s\tremaining: 4m 9s\n",
            "286:\tlearn: 289.6402835\ttotal: 1m 40s\tremaining: 4m 8s\n",
            "287:\tlearn: 289.6211901\ttotal: 1m 40s\tremaining: 4m 8s\n",
            "288:\tlearn: 289.5906039\ttotal: 1m 40s\tremaining: 4m 7s\n",
            "289:\tlearn: 289.5656371\ttotal: 1m 41s\tremaining: 4m 7s\n",
            "290:\tlearn: 289.5331314\ttotal: 1m 41s\tremaining: 4m 6s\n",
            "291:\tlearn: 289.5161673\ttotal: 1m 41s\tremaining: 4m 6s\n",
            "292:\tlearn: 289.4994612\ttotal: 1m 41s\tremaining: 4m 6s\n",
            "293:\tlearn: 289.4709341\ttotal: 1m 42s\tremaining: 4m 5s\n",
            "294:\tlearn: 289.4456813\ttotal: 1m 42s\tremaining: 4m 5s\n",
            "295:\tlearn: 289.4206096\ttotal: 1m 42s\tremaining: 4m 4s\n",
            "296:\tlearn: 289.3847971\ttotal: 1m 43s\tremaining: 4m 4s\n",
            "297:\tlearn: 289.3398836\ttotal: 1m 43s\tremaining: 4m 3s\n",
            "298:\tlearn: 289.2837399\ttotal: 1m 43s\tremaining: 4m 3s\n",
            "299:\tlearn: 289.2509390\ttotal: 1m 44s\tremaining: 4m 3s\n",
            "300:\tlearn: 289.2175427\ttotal: 1m 44s\tremaining: 4m 3s\n",
            "301:\tlearn: 289.1952068\ttotal: 1m 45s\tremaining: 4m 3s\n",
            "302:\tlearn: 289.1691389\ttotal: 1m 45s\tremaining: 4m 3s\n",
            "303:\tlearn: 289.1463680\ttotal: 1m 46s\tremaining: 4m 3s\n",
            "304:\tlearn: 289.1282847\ttotal: 1m 47s\tremaining: 4m 3s\n",
            "305:\tlearn: 289.0990719\ttotal: 1m 47s\tremaining: 4m 4s\n",
            "306:\tlearn: 289.0851471\ttotal: 1m 48s\tremaining: 4m 3s\n",
            "307:\tlearn: 289.0489990\ttotal: 1m 48s\tremaining: 4m 3s\n",
            "308:\tlearn: 289.0272206\ttotal: 1m 48s\tremaining: 4m 2s\n",
            "309:\tlearn: 289.0013135\ttotal: 1m 48s\tremaining: 4m 2s\n",
            "310:\tlearn: 288.9848024\ttotal: 1m 49s\tremaining: 4m 1s\n",
            "311:\tlearn: 288.9632241\ttotal: 1m 49s\tremaining: 4m 1s\n",
            "312:\tlearn: 288.9356942\ttotal: 1m 49s\tremaining: 4m 1s\n",
            "313:\tlearn: 288.9083362\ttotal: 1m 50s\tremaining: 4m\n",
            "314:\tlearn: 288.8740039\ttotal: 1m 50s\tremaining: 4m\n",
            "315:\tlearn: 288.8553928\ttotal: 1m 50s\tremaining: 3m 59s\n",
            "316:\tlearn: 288.8351440\ttotal: 1m 51s\tremaining: 3m 59s\n",
            "317:\tlearn: 288.7754718\ttotal: 1m 51s\tremaining: 3m 58s\n",
            "318:\tlearn: 288.7564179\ttotal: 1m 51s\tremaining: 3m 58s\n",
            "319:\tlearn: 288.7291431\ttotal: 1m 52s\tremaining: 3m 58s\n",
            "320:\tlearn: 288.6933119\ttotal: 1m 52s\tremaining: 3m 57s\n",
            "321:\tlearn: 288.6776863\ttotal: 1m 52s\tremaining: 3m 57s\n",
            "322:\tlearn: 288.6420050\ttotal: 1m 52s\tremaining: 3m 56s\n",
            "323:\tlearn: 288.6276124\ttotal: 1m 53s\tremaining: 3m 56s\n",
            "324:\tlearn: 288.6109863\ttotal: 1m 53s\tremaining: 3m 55s\n",
            "325:\tlearn: 288.5869639\ttotal: 1m 53s\tremaining: 3m 55s\n",
            "326:\tlearn: 288.5514916\ttotal: 1m 54s\tremaining: 3m 55s\n",
            "327:\tlearn: 288.5148696\ttotal: 1m 54s\tremaining: 3m 54s\n",
            "328:\tlearn: 288.4701837\ttotal: 1m 54s\tremaining: 3m 54s\n",
            "329:\tlearn: 288.4461176\ttotal: 1m 55s\tremaining: 3m 53s\n",
            "330:\tlearn: 288.4261423\ttotal: 1m 55s\tremaining: 3m 53s\n",
            "331:\tlearn: 288.4063665\ttotal: 1m 55s\tremaining: 3m 52s\n",
            "332:\tlearn: 288.3784303\ttotal: 1m 55s\tremaining: 3m 52s\n",
            "333:\tlearn: 288.3525884\ttotal: 1m 56s\tremaining: 3m 51s\n",
            "334:\tlearn: 288.3169584\ttotal: 1m 56s\tremaining: 3m 51s\n",
            "335:\tlearn: 288.2852621\ttotal: 1m 56s\tremaining: 3m 50s\n",
            "336:\tlearn: 288.2603988\ttotal: 1m 57s\tremaining: 3m 50s\n",
            "337:\tlearn: 288.2295854\ttotal: 1m 57s\tremaining: 3m 50s\n",
            "338:\tlearn: 288.2137157\ttotal: 1m 57s\tremaining: 3m 49s\n",
            "339:\tlearn: 288.1993905\ttotal: 1m 58s\tremaining: 3m 49s\n",
            "340:\tlearn: 288.1851791\ttotal: 1m 58s\tremaining: 3m 49s\n",
            "341:\tlearn: 288.1489280\ttotal: 1m 59s\tremaining: 3m 49s\n",
            "342:\tlearn: 288.1244570\ttotal: 1m 59s\tremaining: 3m 49s\n",
            "343:\tlearn: 288.0738128\ttotal: 2m\tremaining: 3m 49s\n",
            "344:\tlearn: 288.0555047\ttotal: 2m\tremaining: 3m 49s\n",
            "345:\tlearn: 288.0380023\ttotal: 2m 1s\tremaining: 3m 49s\n",
            "346:\tlearn: 288.0226795\ttotal: 2m 1s\tremaining: 3m 49s\n",
            "347:\tlearn: 287.9916502\ttotal: 2m 2s\tremaining: 3m 48s\n",
            "348:\tlearn: 287.9794663\ttotal: 2m 2s\tremaining: 3m 48s\n",
            "349:\tlearn: 287.9627100\ttotal: 2m 2s\tremaining: 3m 47s\n",
            "350:\tlearn: 287.9510994\ttotal: 2m 2s\tremaining: 3m 47s\n",
            "351:\tlearn: 287.9354991\ttotal: 2m 3s\tremaining: 3m 46s\n",
            "352:\tlearn: 287.9232733\ttotal: 2m 3s\tremaining: 3m 46s\n",
            "353:\tlearn: 287.8867523\ttotal: 2m 3s\tremaining: 3m 45s\n",
            "354:\tlearn: 287.8679066\ttotal: 2m 4s\tremaining: 3m 45s\n",
            "355:\tlearn: 287.8445642\ttotal: 2m 4s\tremaining: 3m 44s\n",
            "356:\tlearn: 287.8066953\ttotal: 2m 4s\tremaining: 3m 44s\n",
            "357:\tlearn: 287.7965363\ttotal: 2m 5s\tremaining: 3m 44s\n",
            "358:\tlearn: 287.7813665\ttotal: 2m 5s\tremaining: 3m 43s\n",
            "359:\tlearn: 287.7595301\ttotal: 2m 5s\tremaining: 3m 43s\n",
            "360:\tlearn: 287.7495871\ttotal: 2m 5s\tremaining: 3m 42s\n",
            "361:\tlearn: 287.7091596\ttotal: 2m 6s\tremaining: 3m 42s\n",
            "362:\tlearn: 287.6909324\ttotal: 2m 6s\tremaining: 3m 42s\n",
            "363:\tlearn: 287.6669332\ttotal: 2m 6s\tremaining: 3m 41s\n",
            "364:\tlearn: 287.6496025\ttotal: 2m 7s\tremaining: 3m 41s\n",
            "365:\tlearn: 287.6247959\ttotal: 2m 7s\tremaining: 3m 40s\n",
            "366:\tlearn: 287.5869921\ttotal: 2m 7s\tremaining: 3m 40s\n",
            "367:\tlearn: 287.5752704\ttotal: 2m 8s\tremaining: 3m 39s\n",
            "368:\tlearn: 287.5596918\ttotal: 2m 8s\tremaining: 3m 39s\n",
            "369:\tlearn: 287.5440283\ttotal: 2m 8s\tremaining: 3m 39s\n",
            "370:\tlearn: 287.5266850\ttotal: 2m 9s\tremaining: 3m 38s\n",
            "371:\tlearn: 287.5148193\ttotal: 2m 9s\tremaining: 3m 38s\n",
            "372:\tlearn: 287.4853945\ttotal: 2m 9s\tremaining: 3m 37s\n",
            "373:\tlearn: 287.4728875\ttotal: 2m 9s\tremaining: 3m 37s\n",
            "374:\tlearn: 287.4536514\ttotal: 2m 10s\tremaining: 3m 37s\n",
            "375:\tlearn: 287.4319655\ttotal: 2m 10s\tremaining: 3m 36s\n",
            "376:\tlearn: 287.4152875\ttotal: 2m 10s\tremaining: 3m 36s\n",
            "377:\tlearn: 287.4022124\ttotal: 2m 11s\tremaining: 3m 36s\n",
            "378:\tlearn: 287.3858088\ttotal: 2m 11s\tremaining: 3m 35s\n",
            "379:\tlearn: 287.3596489\ttotal: 2m 12s\tremaining: 3m 35s\n",
            "380:\tlearn: 287.3331668\ttotal: 2m 12s\tremaining: 3m 35s\n",
            "381:\tlearn: 287.3219000\ttotal: 2m 13s\tremaining: 3m 35s\n",
            "382:\tlearn: 287.3058932\ttotal: 2m 13s\tremaining: 3m 35s\n",
            "383:\tlearn: 287.2761155\ttotal: 2m 14s\tremaining: 3m 35s\n",
            "384:\tlearn: 287.2419842\ttotal: 2m 14s\tremaining: 3m 35s\n",
            "385:\tlearn: 287.2186601\ttotal: 2m 15s\tremaining: 3m 35s\n",
            "386:\tlearn: 287.1971781\ttotal: 2m 15s\tremaining: 3m 35s\n",
            "387:\tlearn: 287.1846703\ttotal: 2m 16s\tremaining: 3m 34s\n",
            "388:\tlearn: 287.1740372\ttotal: 2m 16s\tremaining: 3m 34s\n",
            "389:\tlearn: 287.1651398\ttotal: 2m 16s\tremaining: 3m 33s\n",
            "390:\tlearn: 287.1428964\ttotal: 2m 16s\tremaining: 3m 33s\n",
            "391:\tlearn: 287.1302378\ttotal: 2m 17s\tremaining: 3m 32s\n",
            "392:\tlearn: 287.1006752\ttotal: 2m 17s\tremaining: 3m 32s\n",
            "393:\tlearn: 287.0723868\ttotal: 2m 17s\tremaining: 3m 32s\n",
            "394:\tlearn: 287.0517035\ttotal: 2m 18s\tremaining: 3m 31s\n",
            "395:\tlearn: 287.0304479\ttotal: 2m 18s\tremaining: 3m 31s\n",
            "396:\tlearn: 287.0188589\ttotal: 2m 18s\tremaining: 3m 30s\n",
            "397:\tlearn: 286.9803937\ttotal: 2m 19s\tremaining: 3m 30s\n",
            "398:\tlearn: 286.9646765\ttotal: 2m 19s\tremaining: 3m 30s\n",
            "399:\tlearn: 286.9383378\ttotal: 2m 19s\tremaining: 3m 29s\n",
            "400:\tlearn: 286.9174941\ttotal: 2m 20s\tremaining: 3m 29s\n",
            "401:\tlearn: 286.8906590\ttotal: 2m 20s\tremaining: 3m 28s\n",
            "402:\tlearn: 286.8716222\ttotal: 2m 20s\tremaining: 3m 28s\n",
            "403:\tlearn: 286.8544494\ttotal: 2m 20s\tremaining: 3m 27s\n",
            "404:\tlearn: 286.8395964\ttotal: 2m 21s\tremaining: 3m 27s\n",
            "405:\tlearn: 286.8230245\ttotal: 2m 21s\tremaining: 3m 27s\n",
            "406:\tlearn: 286.8003677\ttotal: 2m 21s\tremaining: 3m 26s\n",
            "407:\tlearn: 286.7890751\ttotal: 2m 22s\tremaining: 3m 26s\n",
            "408:\tlearn: 286.7699278\ttotal: 2m 22s\tremaining: 3m 25s\n",
            "409:\tlearn: 286.7343176\ttotal: 2m 22s\tremaining: 3m 25s\n",
            "410:\tlearn: 286.7125151\ttotal: 2m 23s\tremaining: 3m 25s\n",
            "411:\tlearn: 286.6957283\ttotal: 2m 23s\tremaining: 3m 24s\n",
            "412:\tlearn: 286.6630600\ttotal: 2m 23s\tremaining: 3m 24s\n",
            "413:\tlearn: 286.6487259\ttotal: 2m 23s\tremaining: 3m 23s\n",
            "414:\tlearn: 286.6230448\ttotal: 2m 24s\tremaining: 3m 23s\n",
            "415:\tlearn: 286.5961703\ttotal: 2m 24s\tremaining: 3m 22s\n",
            "416:\tlearn: 286.5568861\ttotal: 2m 24s\tremaining: 3m 22s\n",
            "417:\tlearn: 286.5280832\ttotal: 2m 25s\tremaining: 3m 22s\n",
            "418:\tlearn: 286.5068623\ttotal: 2m 25s\tremaining: 3m 21s\n",
            "419:\tlearn: 286.4957859\ttotal: 2m 26s\tremaining: 3m 21s\n",
            "420:\tlearn: 286.4553646\ttotal: 2m 26s\tremaining: 3m 21s\n",
            "421:\tlearn: 286.4414756\ttotal: 2m 27s\tremaining: 3m 21s\n",
            "422:\tlearn: 286.4142011\ttotal: 2m 27s\tremaining: 3m 21s\n",
            "423:\tlearn: 286.4037216\ttotal: 2m 28s\tremaining: 3m 21s\n",
            "424:\tlearn: 286.3829393\ttotal: 2m 28s\tremaining: 3m 21s\n",
            "425:\tlearn: 286.3620503\ttotal: 2m 29s\tremaining: 3m 20s\n",
            "426:\tlearn: 286.3517739\ttotal: 2m 29s\tremaining: 3m 20s\n",
            "427:\tlearn: 286.3241893\ttotal: 2m 29s\tremaining: 3m 20s\n",
            "428:\tlearn: 286.3056514\ttotal: 2m 30s\tremaining: 3m 19s\n",
            "429:\tlearn: 286.2845910\ttotal: 2m 30s\tremaining: 3m 19s\n",
            "430:\tlearn: 286.2767908\ttotal: 2m 30s\tremaining: 3m 18s\n",
            "431:\tlearn: 286.2622457\ttotal: 2m 30s\tremaining: 3m 18s\n",
            "432:\tlearn: 286.2458246\ttotal: 2m 31s\tremaining: 3m 18s\n",
            "433:\tlearn: 286.2324836\ttotal: 2m 31s\tremaining: 3m 17s\n",
            "434:\tlearn: 286.1882508\ttotal: 2m 31s\tremaining: 3m 17s\n",
            "435:\tlearn: 286.1671378\ttotal: 2m 32s\tremaining: 3m 16s\n",
            "436:\tlearn: 286.1468361\ttotal: 2m 32s\tremaining: 3m 16s\n",
            "437:\tlearn: 286.1255741\ttotal: 2m 32s\tremaining: 3m 16s\n",
            "438:\tlearn: 286.1156089\ttotal: 2m 33s\tremaining: 3m 15s\n",
            "439:\tlearn: 286.0881604\ttotal: 2m 33s\tremaining: 3m 15s\n",
            "440:\tlearn: 286.0745802\ttotal: 2m 33s\tremaining: 3m 14s\n",
            "441:\tlearn: 286.0624522\ttotal: 2m 33s\tremaining: 3m 14s\n",
            "442:\tlearn: 286.0408087\ttotal: 2m 34s\tremaining: 3m 14s\n",
            "443:\tlearn: 286.0298412\ttotal: 2m 34s\tremaining: 3m 13s\n",
            "444:\tlearn: 286.0205169\ttotal: 2m 34s\tremaining: 3m 13s\n",
            "445:\tlearn: 286.0022334\ttotal: 2m 35s\tremaining: 3m 12s\n",
            "446:\tlearn: 285.9831519\ttotal: 2m 35s\tremaining: 3m 12s\n",
            "447:\tlearn: 285.9611124\ttotal: 2m 35s\tremaining: 3m 12s\n",
            "448:\tlearn: 285.9463595\ttotal: 2m 36s\tremaining: 3m 11s\n",
            "449:\tlearn: 285.9311045\ttotal: 2m 36s\tremaining: 3m 11s\n",
            "450:\tlearn: 285.9115354\ttotal: 2m 36s\tremaining: 3m 10s\n",
            "451:\tlearn: 285.8869667\ttotal: 2m 37s\tremaining: 3m 10s\n",
            "452:\tlearn: 285.8774680\ttotal: 2m 37s\tremaining: 3m 10s\n",
            "453:\tlearn: 285.8643342\ttotal: 2m 37s\tremaining: 3m 9s\n",
            "454:\tlearn: 285.8525365\ttotal: 2m 37s\tremaining: 3m 9s\n",
            "455:\tlearn: 285.8397160\ttotal: 2m 38s\tremaining: 3m 8s\n",
            "456:\tlearn: 285.8303113\ttotal: 2m 38s\tremaining: 3m 8s\n",
            "457:\tlearn: 285.8133964\ttotal: 2m 38s\tremaining: 3m 8s\n",
            "458:\tlearn: 285.7826648\ttotal: 2m 39s\tremaining: 3m 7s\n",
            "459:\tlearn: 285.7698250\ttotal: 2m 39s\tremaining: 3m 7s\n",
            "460:\tlearn: 285.7614433\ttotal: 2m 40s\tremaining: 3m 7s\n",
            "461:\tlearn: 285.7497996\ttotal: 2m 40s\tremaining: 3m 7s\n",
            "462:\tlearn: 285.7314270\ttotal: 2m 41s\tremaining: 3m 7s\n",
            "463:\tlearn: 285.7090389\ttotal: 2m 41s\tremaining: 3m 6s\n",
            "464:\tlearn: 285.6892112\ttotal: 2m 42s\tremaining: 3m 6s\n",
            "465:\tlearn: 285.6760509\ttotal: 2m 42s\tremaining: 3m 6s\n",
            "466:\tlearn: 285.6591198\ttotal: 2m 43s\tremaining: 3m 6s\n",
            "467:\tlearn: 285.6520118\ttotal: 2m 43s\tremaining: 3m 5s\n",
            "468:\tlearn: 285.6406550\ttotal: 2m 43s\tremaining: 3m 5s\n",
            "469:\tlearn: 285.6284611\ttotal: 2m 44s\tremaining: 3m 5s\n",
            "470:\tlearn: 285.6171120\ttotal: 2m 44s\tremaining: 3m 4s\n",
            "471:\tlearn: 285.6023657\ttotal: 2m 44s\tremaining: 3m 4s\n",
            "472:\tlearn: 285.5850638\ttotal: 2m 45s\tremaining: 3m 4s\n",
            "473:\tlearn: 285.5685204\ttotal: 2m 45s\tremaining: 3m 3s\n",
            "474:\tlearn: 285.5599058\ttotal: 2m 45s\tremaining: 3m 3s\n",
            "475:\tlearn: 285.5410551\ttotal: 2m 46s\tremaining: 3m 2s\n",
            "476:\tlearn: 285.5266562\ttotal: 2m 46s\tremaining: 3m 2s\n",
            "477:\tlearn: 285.4986163\ttotal: 2m 46s\tremaining: 3m 1s\n",
            "478:\tlearn: 285.4824798\ttotal: 2m 46s\tremaining: 3m 1s\n",
            "479:\tlearn: 285.4694925\ttotal: 2m 47s\tremaining: 3m 1s\n",
            "480:\tlearn: 285.4586257\ttotal: 2m 47s\tremaining: 3m\n",
            "481:\tlearn: 285.4437662\ttotal: 2m 47s\tremaining: 3m\n",
            "482:\tlearn: 285.4371506\ttotal: 2m 48s\tremaining: 2m 59s\n",
            "483:\tlearn: 285.4277817\ttotal: 2m 48s\tremaining: 2m 59s\n",
            "484:\tlearn: 285.4089059\ttotal: 2m 48s\tremaining: 2m 59s\n",
            "485:\tlearn: 285.3989796\ttotal: 2m 49s\tremaining: 2m 58s\n",
            "486:\tlearn: 285.3880835\ttotal: 2m 49s\tremaining: 2m 58s\n",
            "487:\tlearn: 285.3757061\ttotal: 2m 49s\tremaining: 2m 58s\n",
            "488:\tlearn: 285.3649549\ttotal: 2m 50s\tremaining: 2m 57s\n",
            "489:\tlearn: 285.3587629\ttotal: 2m 50s\tremaining: 2m 57s\n",
            "490:\tlearn: 285.3373493\ttotal: 2m 50s\tremaining: 2m 56s\n",
            "491:\tlearn: 285.3286452\ttotal: 2m 51s\tremaining: 2m 56s\n",
            "492:\tlearn: 285.3178552\ttotal: 2m 51s\tremaining: 2m 56s\n",
            "493:\tlearn: 285.3104218\ttotal: 2m 51s\tremaining: 2m 55s\n",
            "494:\tlearn: 285.2983056\ttotal: 2m 52s\tremaining: 2m 55s\n",
            "495:\tlearn: 285.2789536\ttotal: 2m 52s\tremaining: 2m 55s\n",
            "496:\tlearn: 285.2619036\ttotal: 2m 52s\tremaining: 2m 54s\n",
            "497:\tlearn: 285.2421720\ttotal: 2m 52s\tremaining: 2m 54s\n",
            "498:\tlearn: 285.2354194\ttotal: 2m 53s\tremaining: 2m 54s\n",
            "499:\tlearn: 285.2154296\ttotal: 2m 54s\tremaining: 2m 54s\n",
            "500:\tlearn: 285.2043116\ttotal: 2m 54s\tremaining: 2m 53s\n",
            "501:\tlearn: 285.1930534\ttotal: 2m 54s\tremaining: 2m 53s\n",
            "502:\tlearn: 285.1788942\ttotal: 2m 55s\tremaining: 2m 53s\n",
            "503:\tlearn: 285.1666333\ttotal: 2m 56s\tremaining: 2m 53s\n",
            "504:\tlearn: 285.1508088\ttotal: 2m 56s\tremaining: 2m 53s\n",
            "505:\tlearn: 285.1215964\ttotal: 2m 56s\tremaining: 2m 52s\n",
            "506:\tlearn: 285.1069923\ttotal: 2m 57s\tremaining: 2m 52s\n",
            "507:\tlearn: 285.0975268\ttotal: 2m 57s\tremaining: 2m 51s\n",
            "508:\tlearn: 285.0838786\ttotal: 2m 57s\tremaining: 2m 51s\n",
            "509:\tlearn: 285.0695629\ttotal: 2m 58s\tremaining: 2m 51s\n",
            "510:\tlearn: 285.0475578\ttotal: 2m 58s\tremaining: 2m 50s\n",
            "511:\tlearn: 285.0374119\ttotal: 2m 58s\tremaining: 2m 50s\n",
            "512:\tlearn: 285.0237790\ttotal: 2m 59s\tremaining: 2m 50s\n",
            "513:\tlearn: 284.9918187\ttotal: 2m 59s\tremaining: 2m 49s\n",
            "514:\tlearn: 284.9819938\ttotal: 2m 59s\tremaining: 2m 49s\n",
            "515:\tlearn: 284.9731391\ttotal: 3m\tremaining: 2m 49s\n",
            "516:\tlearn: 284.9647019\ttotal: 3m\tremaining: 2m 49s\n",
            "517:\tlearn: 284.9450501\ttotal: 3m 1s\tremaining: 2m 48s\n",
            "518:\tlearn: 284.9279168\ttotal: 3m 1s\tremaining: 2m 48s\n",
            "519:\tlearn: 284.9141055\ttotal: 3m 1s\tremaining: 2m 47s\n",
            "520:\tlearn: 284.9001526\ttotal: 3m 2s\tremaining: 2m 47s\n",
            "521:\tlearn: 284.8840889\ttotal: 3m 2s\tremaining: 2m 47s\n",
            "522:\tlearn: 284.8761748\ttotal: 3m 2s\tremaining: 2m 46s\n",
            "523:\tlearn: 284.8659240\ttotal: 3m 3s\tremaining: 2m 46s\n",
            "524:\tlearn: 284.8484232\ttotal: 3m 3s\tremaining: 2m 45s\n",
            "525:\tlearn: 284.8389735\ttotal: 3m 3s\tremaining: 2m 45s\n",
            "526:\tlearn: 284.8325655\ttotal: 3m 4s\tremaining: 2m 45s\n",
            "527:\tlearn: 284.8187525\ttotal: 3m 4s\tremaining: 2m 44s\n",
            "528:\tlearn: 284.7996822\ttotal: 3m 4s\tremaining: 2m 44s\n",
            "529:\tlearn: 284.7733339\ttotal: 3m 5s\tremaining: 2m 44s\n",
            "530:\tlearn: 284.7617728\ttotal: 3m 5s\tremaining: 2m 43s\n",
            "531:\tlearn: 284.7435246\ttotal: 3m 5s\tremaining: 2m 43s\n",
            "532:\tlearn: 284.7378177\ttotal: 3m 5s\tremaining: 2m 42s\n",
            "533:\tlearn: 284.7253667\ttotal: 3m 6s\tremaining: 2m 42s\n",
            "534:\tlearn: 284.7102639\ttotal: 3m 6s\tremaining: 2m 42s\n",
            "535:\tlearn: 284.6991263\ttotal: 3m 7s\tremaining: 2m 41s\n",
            "536:\tlearn: 284.6886762\ttotal: 3m 7s\tremaining: 2m 41s\n",
            "537:\tlearn: 284.6803665\ttotal: 3m 8s\tremaining: 2m 41s\n",
            "538:\tlearn: 284.6744283\ttotal: 3m 8s\tremaining: 2m 41s\n",
            "539:\tlearn: 284.6636751\ttotal: 3m 9s\tremaining: 2m 41s\n",
            "540:\tlearn: 284.6512463\ttotal: 3m 10s\tremaining: 2m 41s\n",
            "541:\tlearn: 284.6401499\ttotal: 3m 10s\tremaining: 2m 41s\n",
            "542:\tlearn: 284.6281742\ttotal: 3m 11s\tremaining: 2m 40s\n",
            "543:\tlearn: 284.6055357\ttotal: 3m 11s\tremaining: 2m 40s\n",
            "544:\tlearn: 284.5882768\ttotal: 3m 11s\tremaining: 2m 40s\n",
            "545:\tlearn: 284.5752176\ttotal: 3m 12s\tremaining: 2m 39s\n",
            "546:\tlearn: 284.5636219\ttotal: 3m 12s\tremaining: 2m 39s\n",
            "547:\tlearn: 284.5546685\ttotal: 3m 12s\tremaining: 2m 38s\n",
            "548:\tlearn: 284.5404365\ttotal: 3m 12s\tremaining: 2m 38s\n",
            "549:\tlearn: 284.5200781\ttotal: 3m 13s\tremaining: 2m 38s\n",
            "550:\tlearn: 284.5100013\ttotal: 3m 13s\tremaining: 2m 37s\n",
            "551:\tlearn: 284.4935502\ttotal: 3m 13s\tremaining: 2m 37s\n",
            "552:\tlearn: 284.4866832\ttotal: 3m 14s\tremaining: 2m 36s\n",
            "553:\tlearn: 284.4753717\ttotal: 3m 14s\tremaining: 2m 36s\n",
            "554:\tlearn: 284.4639543\ttotal: 3m 14s\tremaining: 2m 36s\n",
            "555:\tlearn: 284.4448002\ttotal: 3m 15s\tremaining: 2m 35s\n",
            "556:\tlearn: 284.4362731\ttotal: 3m 15s\tremaining: 2m 35s\n",
            "557:\tlearn: 284.3985357\ttotal: 3m 15s\tremaining: 2m 35s\n",
            "558:\tlearn: 284.3909886\ttotal: 3m 16s\tremaining: 2m 34s\n",
            "559:\tlearn: 284.3815264\ttotal: 3m 16s\tremaining: 2m 34s\n",
            "560:\tlearn: 284.3700527\ttotal: 3m 16s\tremaining: 2m 33s\n",
            "561:\tlearn: 284.3516870\ttotal: 3m 17s\tremaining: 2m 33s\n",
            "562:\tlearn: 284.3385621\ttotal: 3m 17s\tremaining: 2m 33s\n",
            "563:\tlearn: 284.3176488\ttotal: 3m 17s\tremaining: 2m 32s\n",
            "564:\tlearn: 284.3087345\ttotal: 3m 17s\tremaining: 2m 32s\n",
            "565:\tlearn: 284.3012932\ttotal: 3m 18s\tremaining: 2m 32s\n",
            "566:\tlearn: 284.2924648\ttotal: 3m 18s\tremaining: 2m 31s\n",
            "567:\tlearn: 284.2823192\ttotal: 3m 18s\tremaining: 2m 31s\n",
            "568:\tlearn: 284.2716817\ttotal: 3m 19s\tremaining: 2m 30s\n",
            "569:\tlearn: 284.2659475\ttotal: 3m 19s\tremaining: 2m 30s\n",
            "570:\tlearn: 284.2557858\ttotal: 3m 19s\tremaining: 2m 30s\n",
            "571:\tlearn: 284.2510979\ttotal: 3m 20s\tremaining: 2m 29s\n",
            "572:\tlearn: 284.2302648\ttotal: 3m 20s\tremaining: 2m 29s\n",
            "573:\tlearn: 284.2105180\ttotal: 3m 20s\tremaining: 2m 29s\n",
            "574:\tlearn: 284.2043082\ttotal: 3m 21s\tremaining: 2m 28s\n",
            "575:\tlearn: 284.1972096\ttotal: 3m 22s\tremaining: 2m 28s\n",
            "576:\tlearn: 284.1898078\ttotal: 3m 22s\tremaining: 2m 28s\n",
            "577:\tlearn: 284.1778997\ttotal: 3m 23s\tremaining: 2m 28s\n",
            "578:\tlearn: 284.1672270\ttotal: 3m 23s\tremaining: 2m 28s\n",
            "579:\tlearn: 284.1542328\ttotal: 3m 24s\tremaining: 2m 27s\n",
            "580:\tlearn: 284.1403975\ttotal: 3m 24s\tremaining: 2m 27s\n",
            "581:\tlearn: 284.1237724\ttotal: 3m 24s\tremaining: 2m 27s\n",
            "582:\tlearn: 284.1161713\ttotal: 3m 25s\tremaining: 2m 26s\n",
            "583:\tlearn: 284.1095304\ttotal: 3m 25s\tremaining: 2m 26s\n",
            "584:\tlearn: 284.0951674\ttotal: 3m 25s\tremaining: 2m 25s\n",
            "585:\tlearn: 284.0825494\ttotal: 3m 26s\tremaining: 2m 25s\n",
            "586:\tlearn: 284.0741012\ttotal: 3m 26s\tremaining: 2m 25s\n",
            "587:\tlearn: 284.0692121\ttotal: 3m 26s\tremaining: 2m 24s\n",
            "588:\tlearn: 284.0543051\ttotal: 3m 26s\tremaining: 2m 24s\n",
            "589:\tlearn: 284.0410994\ttotal: 3m 27s\tremaining: 2m 24s\n",
            "590:\tlearn: 284.0313428\ttotal: 3m 27s\tremaining: 2m 23s\n",
            "591:\tlearn: 284.0131120\ttotal: 3m 27s\tremaining: 2m 23s\n",
            "592:\tlearn: 283.9941856\ttotal: 3m 28s\tremaining: 2m 22s\n",
            "593:\tlearn: 283.9850456\ttotal: 3m 28s\tremaining: 2m 22s\n",
            "594:\tlearn: 283.9741198\ttotal: 3m 28s\tremaining: 2m 22s\n",
            "595:\tlearn: 283.9689055\ttotal: 3m 29s\tremaining: 2m 21s\n",
            "596:\tlearn: 283.9644973\ttotal: 3m 29s\tremaining: 2m 21s\n",
            "597:\tlearn: 283.9520386\ttotal: 3m 29s\tremaining: 2m 20s\n",
            "598:\tlearn: 283.9367904\ttotal: 3m 29s\tremaining: 2m 20s\n",
            "599:\tlearn: 283.9231751\ttotal: 3m 30s\tremaining: 2m 20s\n",
            "600:\tlearn: 283.9133732\ttotal: 3m 30s\tremaining: 2m 19s\n",
            "601:\tlearn: 283.9071105\ttotal: 3m 30s\tremaining: 2m 19s\n",
            "602:\tlearn: 283.8914759\ttotal: 3m 31s\tremaining: 2m 19s\n",
            "603:\tlearn: 283.8809982\ttotal: 3m 31s\tremaining: 2m 18s\n",
            "604:\tlearn: 283.8664650\ttotal: 3m 31s\tremaining: 2m 18s\n",
            "605:\tlearn: 283.8589327\ttotal: 3m 32s\tremaining: 2m 17s\n",
            "606:\tlearn: 283.8364796\ttotal: 3m 32s\tremaining: 2m 17s\n",
            "607:\tlearn: 283.8220967\ttotal: 3m 32s\tremaining: 2m 17s\n",
            "608:\tlearn: 283.8114419\ttotal: 3m 33s\tremaining: 2m 16s\n",
            "609:\tlearn: 283.8015670\ttotal: 3m 33s\tremaining: 2m 16s\n",
            "610:\tlearn: 283.7940930\ttotal: 3m 33s\tremaining: 2m 16s\n",
            "611:\tlearn: 283.7866480\ttotal: 3m 34s\tremaining: 2m 15s\n",
            "612:\tlearn: 283.7700834\ttotal: 3m 34s\tremaining: 2m 15s\n",
            "613:\tlearn: 283.7476010\ttotal: 3m 34s\tremaining: 2m 15s\n",
            "614:\tlearn: 283.7353004\ttotal: 3m 35s\tremaining: 2m 14s\n",
            "615:\tlearn: 283.7258903\ttotal: 3m 36s\tremaining: 2m 14s\n",
            "616:\tlearn: 283.7199026\ttotal: 3m 36s\tremaining: 2m 14s\n",
            "617:\tlearn: 283.7026440\ttotal: 3m 37s\tremaining: 2m 14s\n",
            "618:\tlearn: 283.6935913\ttotal: 3m 37s\tremaining: 2m 14s\n",
            "619:\tlearn: 283.6843852\ttotal: 3m 38s\tremaining: 2m 13s\n",
            "620:\tlearn: 283.6670865\ttotal: 3m 38s\tremaining: 2m 13s\n",
            "621:\tlearn: 283.6564892\ttotal: 3m 38s\tremaining: 2m 12s\n",
            "622:\tlearn: 283.6504940\ttotal: 3m 39s\tremaining: 2m 12s\n",
            "623:\tlearn: 283.6400505\ttotal: 3m 39s\tremaining: 2m 12s\n",
            "624:\tlearn: 283.6282381\ttotal: 3m 39s\tremaining: 2m 11s\n",
            "625:\tlearn: 283.6244695\ttotal: 3m 40s\tremaining: 2m 11s\n",
            "626:\tlearn: 283.6097916\ttotal: 3m 40s\tremaining: 2m 11s\n",
            "627:\tlearn: 283.6025036\ttotal: 3m 40s\tremaining: 2m 10s\n",
            "628:\tlearn: 283.5878497\ttotal: 3m 40s\tremaining: 2m 10s\n",
            "629:\tlearn: 283.5695226\ttotal: 3m 41s\tremaining: 2m 9s\n",
            "630:\tlearn: 283.5578863\ttotal: 3m 41s\tremaining: 2m 9s\n",
            "631:\tlearn: 283.5443868\ttotal: 3m 41s\tremaining: 2m 9s\n",
            "632:\tlearn: 283.5338226\ttotal: 3m 42s\tremaining: 2m 8s\n",
            "633:\tlearn: 283.5227838\ttotal: 3m 42s\tremaining: 2m 8s\n",
            "634:\tlearn: 283.5174548\ttotal: 3m 42s\tremaining: 2m 8s\n",
            "635:\tlearn: 283.5061636\ttotal: 3m 43s\tremaining: 2m 7s\n",
            "636:\tlearn: 283.4987568\ttotal: 3m 43s\tremaining: 2m 7s\n",
            "637:\tlearn: 283.4933294\ttotal: 3m 43s\tremaining: 2m 6s\n",
            "638:\tlearn: 283.4860196\ttotal: 3m 44s\tremaining: 2m 6s\n",
            "639:\tlearn: 283.4761533\ttotal: 3m 44s\tremaining: 2m 6s\n",
            "640:\tlearn: 283.4610456\ttotal: 3m 44s\tremaining: 2m 5s\n",
            "641:\tlearn: 283.4547593\ttotal: 3m 44s\tremaining: 2m 5s\n",
            "642:\tlearn: 283.4353201\ttotal: 3m 45s\tremaining: 2m 5s\n",
            "643:\tlearn: 283.4236220\ttotal: 3m 45s\tremaining: 2m 4s\n",
            "644:\tlearn: 283.4113503\ttotal: 3m 45s\tremaining: 2m 4s\n",
            "645:\tlearn: 283.4014673\ttotal: 3m 46s\tremaining: 2m 3s\n",
            "646:\tlearn: 283.3925849\ttotal: 3m 46s\tremaining: 2m 3s\n",
            "647:\tlearn: 283.3783163\ttotal: 3m 46s\tremaining: 2m 3s\n",
            "648:\tlearn: 283.3724197\ttotal: 3m 47s\tremaining: 2m 2s\n",
            "649:\tlearn: 283.3636886\ttotal: 3m 47s\tremaining: 2m 2s\n",
            "650:\tlearn: 283.3556564\ttotal: 3m 47s\tremaining: 2m 2s\n",
            "651:\tlearn: 283.3291843\ttotal: 3m 48s\tremaining: 2m 1s\n",
            "652:\tlearn: 283.3161420\ttotal: 3m 48s\tremaining: 2m 1s\n",
            "653:\tlearn: 283.3095381\ttotal: 3m 49s\tremaining: 2m 1s\n",
            "654:\tlearn: 283.2981624\ttotal: 3m 49s\tremaining: 2m\n",
            "655:\tlearn: 283.2896971\ttotal: 3m 50s\tremaining: 2m\n",
            "656:\tlearn: 283.2782862\ttotal: 3m 50s\tremaining: 2m\n",
            "657:\tlearn: 283.2671882\ttotal: 3m 51s\tremaining: 2m\n",
            "658:\tlearn: 283.2574899\ttotal: 3m 51s\tremaining: 1m 59s\n",
            "659:\tlearn: 283.2517021\ttotal: 3m 52s\tremaining: 1m 59s\n",
            "660:\tlearn: 283.2335569\ttotal: 3m 52s\tremaining: 1m 59s\n",
            "661:\tlearn: 283.2292012\ttotal: 3m 52s\tremaining: 1m 58s\n",
            "662:\tlearn: 283.2206902\ttotal: 3m 53s\tremaining: 1m 58s\n",
            "663:\tlearn: 283.2120736\ttotal: 3m 53s\tremaining: 1m 58s\n",
            "664:\tlearn: 283.2061536\ttotal: 3m 53s\tremaining: 1m 57s\n",
            "665:\tlearn: 283.1954500\ttotal: 3m 53s\tremaining: 1m 57s\n",
            "666:\tlearn: 283.1892827\ttotal: 3m 54s\tremaining: 1m 56s\n",
            "667:\tlearn: 283.1844475\ttotal: 3m 54s\tremaining: 1m 56s\n",
            "668:\tlearn: 283.1729835\ttotal: 3m 54s\tremaining: 1m 56s\n",
            "669:\tlearn: 283.1607974\ttotal: 3m 55s\tremaining: 1m 55s\n",
            "670:\tlearn: 283.1527032\ttotal: 3m 55s\tremaining: 1m 55s\n",
            "671:\tlearn: 283.1427699\ttotal: 3m 55s\tremaining: 1m 55s\n",
            "672:\tlearn: 283.1154621\ttotal: 3m 56s\tremaining: 1m 54s\n",
            "673:\tlearn: 283.0975636\ttotal: 3m 56s\tremaining: 1m 54s\n",
            "674:\tlearn: 283.0737989\ttotal: 3m 56s\tremaining: 1m 53s\n",
            "675:\tlearn: 283.0607558\ttotal: 3m 57s\tremaining: 1m 53s\n",
            "676:\tlearn: 283.0525962\ttotal: 3m 57s\tremaining: 1m 53s\n",
            "677:\tlearn: 283.0397456\ttotal: 3m 57s\tremaining: 1m 52s\n",
            "678:\tlearn: 283.0365375\ttotal: 3m 57s\tremaining: 1m 52s\n",
            "679:\tlearn: 283.0239914\ttotal: 3m 58s\tremaining: 1m 52s\n",
            "680:\tlearn: 283.0160378\ttotal: 3m 58s\tremaining: 1m 51s\n",
            "681:\tlearn: 282.9966461\ttotal: 3m 58s\tremaining: 1m 51s\n",
            "682:\tlearn: 282.9674040\ttotal: 3m 59s\tremaining: 1m 51s\n",
            "683:\tlearn: 282.9492050\ttotal: 3m 59s\tremaining: 1m 50s\n",
            "684:\tlearn: 282.9422231\ttotal: 3m 59s\tremaining: 1m 50s\n",
            "685:\tlearn: 282.9335304\ttotal: 4m\tremaining: 1m 49s\n",
            "686:\tlearn: 282.9064150\ttotal: 4m\tremaining: 1m 49s\n",
            "687:\tlearn: 282.8926476\ttotal: 4m\tremaining: 1m 49s\n",
            "688:\tlearn: 282.8827203\ttotal: 4m 1s\tremaining: 1m 48s\n",
            "689:\tlearn: 282.8731256\ttotal: 4m 1s\tremaining: 1m 48s\n",
            "690:\tlearn: 282.8670412\ttotal: 4m 1s\tremaining: 1m 48s\n",
            "691:\tlearn: 282.8575647\ttotal: 4m 2s\tremaining: 1m 47s\n",
            "692:\tlearn: 282.8466329\ttotal: 4m 2s\tremaining: 1m 47s\n",
            "693:\tlearn: 282.8229501\ttotal: 4m 3s\tremaining: 1m 47s\n",
            "694:\tlearn: 282.8156479\ttotal: 4m 3s\tremaining: 1m 46s\n",
            "695:\tlearn: 282.7986080\ttotal: 4m 4s\tremaining: 1m 46s\n",
            "696:\tlearn: 282.7907680\ttotal: 4m 4s\tremaining: 1m 46s\n",
            "697:\tlearn: 282.7818163\ttotal: 4m 5s\tremaining: 1m 46s\n",
            "698:\tlearn: 282.7733573\ttotal: 4m 5s\tremaining: 1m 45s\n",
            "699:\tlearn: 282.7601574\ttotal: 4m 6s\tremaining: 1m 45s\n",
            "700:\tlearn: 282.7502461\ttotal: 4m 6s\tremaining: 1m 45s\n",
            "701:\tlearn: 282.7419033\ttotal: 4m 6s\tremaining: 1m 44s\n",
            "702:\tlearn: 282.7367459\ttotal: 4m 7s\tremaining: 1m 44s\n",
            "703:\tlearn: 282.7320959\ttotal: 4m 7s\tremaining: 1m 44s\n",
            "704:\tlearn: 282.7236912\ttotal: 4m 7s\tremaining: 1m 43s\n",
            "705:\tlearn: 282.7133631\ttotal: 4m 7s\tremaining: 1m 43s\n",
            "706:\tlearn: 282.7013984\ttotal: 4m 8s\tremaining: 1m 42s\n",
            "707:\tlearn: 282.6956040\ttotal: 4m 8s\tremaining: 1m 42s\n",
            "708:\tlearn: 282.6894367\ttotal: 4m 8s\tremaining: 1m 42s\n",
            "709:\tlearn: 282.6675552\ttotal: 4m 9s\tremaining: 1m 41s\n",
            "710:\tlearn: 282.6593014\ttotal: 4m 9s\tremaining: 1m 41s\n",
            "711:\tlearn: 282.6481124\ttotal: 4m 9s\tremaining: 1m 41s\n",
            "712:\tlearn: 282.6369663\ttotal: 4m 10s\tremaining: 1m 40s\n",
            "713:\tlearn: 282.6142612\ttotal: 4m 10s\tremaining: 1m 40s\n",
            "714:\tlearn: 282.6022108\ttotal: 4m 10s\tremaining: 1m 39s\n",
            "715:\tlearn: 282.5897264\ttotal: 4m 11s\tremaining: 1m 39s\n",
            "716:\tlearn: 282.5799678\ttotal: 4m 11s\tremaining: 1m 39s\n",
            "717:\tlearn: 282.5697852\ttotal: 4m 11s\tremaining: 1m 38s\n",
            "718:\tlearn: 282.5632966\ttotal: 4m 12s\tremaining: 1m 38s\n",
            "719:\tlearn: 282.5500078\ttotal: 4m 12s\tremaining: 1m 38s\n",
            "720:\tlearn: 282.5393712\ttotal: 4m 12s\tremaining: 1m 37s\n",
            "721:\tlearn: 282.5311868\ttotal: 4m 12s\tremaining: 1m 37s\n",
            "722:\tlearn: 282.5245012\ttotal: 4m 13s\tremaining: 1m 37s\n",
            "723:\tlearn: 282.5174995\ttotal: 4m 13s\tremaining: 1m 36s\n",
            "724:\tlearn: 282.5096469\ttotal: 4m 13s\tremaining: 1m 36s\n",
            "725:\tlearn: 282.4997154\ttotal: 4m 14s\tremaining: 1m 35s\n",
            "726:\tlearn: 282.4931779\ttotal: 4m 14s\tremaining: 1m 35s\n",
            "727:\tlearn: 282.4820047\ttotal: 4m 14s\tremaining: 1m 35s\n",
            "728:\tlearn: 282.4763073\ttotal: 4m 15s\tremaining: 1m 34s\n",
            "729:\tlearn: 282.4599465\ttotal: 4m 15s\tremaining: 1m 34s\n",
            "730:\tlearn: 282.4456815\ttotal: 4m 15s\tremaining: 1m 34s\n",
            "731:\tlearn: 282.4384683\ttotal: 4m 16s\tremaining: 1m 33s\n",
            "732:\tlearn: 282.4335231\ttotal: 4m 16s\tremaining: 1m 33s\n",
            "733:\tlearn: 282.4186440\ttotal: 4m 17s\tremaining: 1m 33s\n",
            "734:\tlearn: 282.4134896\ttotal: 4m 17s\tremaining: 1m 32s\n",
            "735:\tlearn: 282.4053987\ttotal: 4m 18s\tremaining: 1m 32s\n",
            "736:\tlearn: 282.3841602\ttotal: 4m 18s\tremaining: 1m 32s\n",
            "737:\tlearn: 282.3731911\ttotal: 4m 19s\tremaining: 1m 32s\n",
            "738:\tlearn: 282.3563077\ttotal: 4m 19s\tremaining: 1m 31s\n",
            "739:\tlearn: 282.3348380\ttotal: 4m 20s\tremaining: 1m 31s\n",
            "740:\tlearn: 282.3285293\ttotal: 4m 20s\tremaining: 1m 31s\n",
            "741:\tlearn: 282.3208113\ttotal: 4m 20s\tremaining: 1m 30s\n",
            "742:\tlearn: 282.3058004\ttotal: 4m 20s\tremaining: 1m 30s\n",
            "743:\tlearn: 282.2816117\ttotal: 4m 21s\tremaining: 1m 29s\n",
            "744:\tlearn: 282.2700458\ttotal: 4m 21s\tremaining: 1m 29s\n",
            "745:\tlearn: 282.2621912\ttotal: 4m 21s\tremaining: 1m 29s\n",
            "746:\tlearn: 282.2524918\ttotal: 4m 22s\tremaining: 1m 28s\n",
            "747:\tlearn: 282.2455425\ttotal: 4m 22s\tremaining: 1m 28s\n",
            "748:\tlearn: 282.2273742\ttotal: 4m 22s\tremaining: 1m 28s\n",
            "749:\tlearn: 282.2178151\ttotal: 4m 23s\tremaining: 1m 27s\n",
            "750:\tlearn: 282.2098874\ttotal: 4m 23s\tremaining: 1m 27s\n",
            "751:\tlearn: 282.1968240\ttotal: 4m 23s\tremaining: 1m 27s\n",
            "752:\tlearn: 282.1818891\ttotal: 4m 24s\tremaining: 1m 26s\n",
            "753:\tlearn: 282.1719153\ttotal: 4m 24s\tremaining: 1m 26s\n",
            "754:\tlearn: 282.1610431\ttotal: 4m 24s\tremaining: 1m 25s\n",
            "755:\tlearn: 282.1548811\ttotal: 4m 25s\tremaining: 1m 25s\n",
            "756:\tlearn: 282.1356276\ttotal: 4m 25s\tremaining: 1m 25s\n",
            "757:\tlearn: 282.1258181\ttotal: 4m 25s\tremaining: 1m 24s\n",
            "758:\tlearn: 282.1098080\ttotal: 4m 26s\tremaining: 1m 24s\n",
            "759:\tlearn: 282.0987780\ttotal: 4m 26s\tremaining: 1m 24s\n",
            "760:\tlearn: 282.0935481\ttotal: 4m 26s\tremaining: 1m 23s\n",
            "761:\tlearn: 282.0857613\ttotal: 4m 26s\tremaining: 1m 23s\n",
            "762:\tlearn: 282.0758266\ttotal: 4m 27s\tremaining: 1m 23s\n",
            "763:\tlearn: 282.0633452\ttotal: 4m 27s\tremaining: 1m 22s\n",
            "764:\tlearn: 282.0550425\ttotal: 4m 27s\tremaining: 1m 22s\n",
            "765:\tlearn: 282.0445716\ttotal: 4m 28s\tremaining: 1m 21s\n",
            "766:\tlearn: 282.0297749\ttotal: 4m 28s\tremaining: 1m 21s\n",
            "767:\tlearn: 282.0215587\ttotal: 4m 28s\tremaining: 1m 21s\n",
            "768:\tlearn: 282.0108629\ttotal: 4m 29s\tremaining: 1m 20s\n",
            "769:\tlearn: 282.0049887\ttotal: 4m 29s\tremaining: 1m 20s\n",
            "770:\tlearn: 281.9972321\ttotal: 4m 30s\tremaining: 1m 20s\n",
            "771:\tlearn: 281.9782278\ttotal: 4m 30s\tremaining: 1m 19s\n",
            "772:\tlearn: 281.9604564\ttotal: 4m 31s\tremaining: 1m 19s\n",
            "773:\tlearn: 281.9511222\ttotal: 4m 31s\tremaining: 1m 19s\n",
            "774:\tlearn: 281.9444950\ttotal: 4m 32s\tremaining: 1m 19s\n",
            "775:\tlearn: 281.9308955\ttotal: 4m 33s\tremaining: 1m 18s\n",
            "776:\tlearn: 281.9191863\ttotal: 4m 33s\tremaining: 1m 18s\n",
            "777:\tlearn: 281.9019674\ttotal: 4m 33s\tremaining: 1m 18s\n",
            "778:\tlearn: 281.8914740\ttotal: 4m 33s\tremaining: 1m 17s\n",
            "779:\tlearn: 281.8782187\ttotal: 4m 34s\tremaining: 1m 17s\n",
            "780:\tlearn: 281.8732629\ttotal: 4m 34s\tremaining: 1m 16s\n",
            "781:\tlearn: 281.8657912\ttotal: 4m 34s\tremaining: 1m 16s\n",
            "782:\tlearn: 281.8584614\ttotal: 4m 35s\tremaining: 1m 16s\n",
            "783:\tlearn: 281.8472906\ttotal: 4m 35s\tremaining: 1m 15s\n",
            "784:\tlearn: 281.8399561\ttotal: 4m 35s\tremaining: 1m 15s\n",
            "785:\tlearn: 281.8218453\ttotal: 4m 36s\tremaining: 1m 15s\n",
            "786:\tlearn: 281.8160908\ttotal: 4m 36s\tremaining: 1m 14s\n",
            "787:\tlearn: 281.8089777\ttotal: 4m 36s\tremaining: 1m 14s\n",
            "788:\tlearn: 281.8058327\ttotal: 4m 36s\tremaining: 1m 14s\n",
            "789:\tlearn: 281.7971846\ttotal: 4m 37s\tremaining: 1m 13s\n",
            "790:\tlearn: 281.7848218\ttotal: 4m 37s\tremaining: 1m 13s\n",
            "791:\tlearn: 281.7780001\ttotal: 4m 37s\tremaining: 1m 12s\n",
            "792:\tlearn: 281.7645579\ttotal: 4m 38s\tremaining: 1m 12s\n",
            "793:\tlearn: 281.7561715\ttotal: 4m 38s\tremaining: 1m 12s\n",
            "794:\tlearn: 281.7474505\ttotal: 4m 38s\tremaining: 1m 11s\n",
            "795:\tlearn: 281.7375612\ttotal: 4m 39s\tremaining: 1m 11s\n",
            "796:\tlearn: 281.7308252\ttotal: 4m 39s\tremaining: 1m 11s\n",
            "797:\tlearn: 281.7244044\ttotal: 4m 39s\tremaining: 1m 10s\n",
            "798:\tlearn: 281.7139827\ttotal: 4m 39s\tremaining: 1m 10s\n",
            "799:\tlearn: 281.7092864\ttotal: 4m 40s\tremaining: 1m 10s\n",
            "800:\tlearn: 281.7035195\ttotal: 4m 40s\tremaining: 1m 9s\n",
            "801:\tlearn: 281.6938553\ttotal: 4m 40s\tremaining: 1m 9s\n",
            "802:\tlearn: 281.6823156\ttotal: 4m 41s\tremaining: 1m 9s\n",
            "803:\tlearn: 281.6690282\ttotal: 4m 41s\tremaining: 1m 8s\n",
            "804:\tlearn: 281.6612527\ttotal: 4m 41s\tremaining: 1m 8s\n",
            "805:\tlearn: 281.6419429\ttotal: 4m 42s\tremaining: 1m 7s\n",
            "806:\tlearn: 281.6287835\ttotal: 4m 42s\tremaining: 1m 7s\n",
            "807:\tlearn: 281.6224627\ttotal: 4m 42s\tremaining: 1m 7s\n",
            "808:\tlearn: 281.6138650\ttotal: 4m 43s\tremaining: 1m 6s\n",
            "809:\tlearn: 281.6035756\ttotal: 4m 43s\tremaining: 1m 6s\n",
            "810:\tlearn: 281.5942431\ttotal: 4m 44s\tremaining: 1m 6s\n",
            "811:\tlearn: 281.5816831\ttotal: 4m 44s\tremaining: 1m 5s\n",
            "812:\tlearn: 281.5783071\ttotal: 4m 45s\tremaining: 1m 5s\n",
            "813:\tlearn: 281.5722839\ttotal: 4m 45s\tremaining: 1m 5s\n",
            "814:\tlearn: 281.5599229\ttotal: 4m 46s\tremaining: 1m 4s\n",
            "815:\tlearn: 281.5533903\ttotal: 4m 46s\tremaining: 1m 4s\n",
            "816:\tlearn: 281.5468354\ttotal: 4m 47s\tremaining: 1m 4s\n",
            "817:\tlearn: 281.5427982\ttotal: 4m 47s\tremaining: 1m 3s\n",
            "818:\tlearn: 281.5324670\ttotal: 4m 47s\tremaining: 1m 3s\n",
            "819:\tlearn: 281.5175825\ttotal: 4m 48s\tremaining: 1m 3s\n",
            "820:\tlearn: 281.5081551\ttotal: 4m 48s\tremaining: 1m 2s\n",
            "821:\tlearn: 281.4966564\ttotal: 4m 48s\tremaining: 1m 2s\n",
            "822:\tlearn: 281.4906695\ttotal: 4m 49s\tremaining: 1m 2s\n",
            "823:\tlearn: 281.4674323\ttotal: 4m 49s\tremaining: 1m 1s\n",
            "824:\tlearn: 281.4608357\ttotal: 4m 49s\tremaining: 1m 1s\n",
            "825:\tlearn: 281.4512300\ttotal: 4m 49s\tremaining: 1m 1s\n",
            "826:\tlearn: 281.4474454\ttotal: 4m 50s\tremaining: 1m\n",
            "827:\tlearn: 281.4340807\ttotal: 4m 50s\tremaining: 1m\n",
            "828:\tlearn: 281.4272294\ttotal: 4m 50s\tremaining: 60s\n",
            "829:\tlearn: 281.4173938\ttotal: 4m 51s\tremaining: 59.6s\n",
            "830:\tlearn: 281.4146566\ttotal: 4m 51s\tremaining: 59.3s\n",
            "831:\tlearn: 281.4072726\ttotal: 4m 51s\tremaining: 58.9s\n",
            "832:\tlearn: 281.4028790\ttotal: 4m 52s\tremaining: 58.6s\n",
            "833:\tlearn: 281.3991535\ttotal: 4m 52s\tremaining: 58.2s\n",
            "834:\tlearn: 281.3900836\ttotal: 4m 52s\tremaining: 57.8s\n",
            "835:\tlearn: 281.3758053\ttotal: 4m 52s\tremaining: 57.5s\n",
            "836:\tlearn: 281.3659902\ttotal: 4m 53s\tremaining: 57.1s\n",
            "837:\tlearn: 281.3617945\ttotal: 4m 53s\tremaining: 56.8s\n",
            "838:\tlearn: 281.3361787\ttotal: 4m 53s\tremaining: 56.4s\n",
            "839:\tlearn: 281.3277684\ttotal: 4m 54s\tremaining: 56s\n",
            "840:\tlearn: 281.3209780\ttotal: 4m 54s\tremaining: 55.7s\n",
            "841:\tlearn: 281.3054968\ttotal: 4m 54s\tremaining: 55.3s\n",
            "842:\tlearn: 281.3010851\ttotal: 4m 55s\tremaining: 55s\n",
            "843:\tlearn: 281.2937445\ttotal: 4m 55s\tremaining: 54.6s\n",
            "844:\tlearn: 281.2787377\ttotal: 4m 55s\tremaining: 54.3s\n",
            "845:\tlearn: 281.2676843\ttotal: 4m 56s\tremaining: 53.9s\n",
            "846:\tlearn: 281.2575538\ttotal: 4m 56s\tremaining: 53.6s\n",
            "847:\tlearn: 281.2485978\ttotal: 4m 56s\tremaining: 53.2s\n",
            "848:\tlearn: 281.2437363\ttotal: 4m 57s\tremaining: 52.9s\n",
            "849:\tlearn: 281.2360741\ttotal: 4m 57s\tremaining: 52.5s\n",
            "850:\tlearn: 281.2292363\ttotal: 4m 58s\tremaining: 52.2s\n",
            "851:\tlearn: 281.2130498\ttotal: 4m 58s\tremaining: 51.9s\n",
            "852:\tlearn: 281.2054972\ttotal: 4m 59s\tremaining: 51.6s\n",
            "853:\tlearn: 281.2031709\ttotal: 4m 59s\tremaining: 51.2s\n",
            "854:\tlearn: 281.1930055\ttotal: 5m\tremaining: 50.9s\n",
            "855:\tlearn: 281.1858094\ttotal: 5m\tremaining: 50.6s\n",
            "856:\tlearn: 281.1764503\ttotal: 5m 1s\tremaining: 50.3s\n",
            "857:\tlearn: 281.1642438\ttotal: 5m 1s\tremaining: 49.9s\n",
            "858:\tlearn: 281.1599410\ttotal: 5m 1s\tremaining: 49.5s\n",
            "859:\tlearn: 281.1514244\ttotal: 5m 2s\tremaining: 49.2s\n",
            "860:\tlearn: 281.1435809\ttotal: 5m 2s\tremaining: 48.8s\n",
            "861:\tlearn: 281.1319191\ttotal: 5m 2s\tremaining: 48.5s\n",
            "862:\tlearn: 281.1278634\ttotal: 5m 2s\tremaining: 48.1s\n",
            "863:\tlearn: 281.1185859\ttotal: 5m 3s\tremaining: 47.7s\n",
            "864:\tlearn: 281.1090934\ttotal: 5m 3s\tremaining: 47.4s\n",
            "865:\tlearn: 281.0994906\ttotal: 5m 3s\tremaining: 47s\n",
            "866:\tlearn: 281.0845623\ttotal: 5m 4s\tremaining: 46.7s\n",
            "867:\tlearn: 281.0709509\ttotal: 5m 4s\tremaining: 46.3s\n",
            "868:\tlearn: 281.0518398\ttotal: 5m 4s\tremaining: 46s\n",
            "869:\tlearn: 281.0461381\ttotal: 5m 5s\tremaining: 45.6s\n",
            "870:\tlearn: 281.0364534\ttotal: 5m 5s\tremaining: 45.2s\n",
            "871:\tlearn: 281.0307522\ttotal: 5m 5s\tremaining: 44.9s\n",
            "872:\tlearn: 281.0275044\ttotal: 5m 6s\tremaining: 44.5s\n",
            "873:\tlearn: 281.0231788\ttotal: 5m 6s\tremaining: 44.2s\n",
            "874:\tlearn: 281.0127668\ttotal: 5m 6s\tremaining: 43.8s\n",
            "875:\tlearn: 280.9951574\ttotal: 5m 7s\tremaining: 43.5s\n",
            "876:\tlearn: 280.9904636\ttotal: 5m 7s\tremaining: 43.1s\n",
            "877:\tlearn: 280.9795618\ttotal: 5m 7s\tremaining: 42.7s\n",
            "878:\tlearn: 280.9713967\ttotal: 5m 7s\tremaining: 42.4s\n",
            "879:\tlearn: 280.9654807\ttotal: 5m 8s\tremaining: 42s\n",
            "880:\tlearn: 280.9429211\ttotal: 5m 8s\tremaining: 41.7s\n",
            "881:\tlearn: 280.9353029\ttotal: 5m 8s\tremaining: 41.3s\n",
            "882:\tlearn: 280.9292367\ttotal: 5m 9s\tremaining: 41s\n",
            "883:\tlearn: 280.9248254\ttotal: 5m 9s\tremaining: 40.6s\n",
            "884:\tlearn: 280.9170095\ttotal: 5m 9s\tremaining: 40.3s\n",
            "885:\tlearn: 280.9114058\ttotal: 5m 10s\tremaining: 39.9s\n",
            "886:\tlearn: 280.9051906\ttotal: 5m 10s\tremaining: 39.6s\n",
            "887:\tlearn: 280.9000431\ttotal: 5m 10s\tremaining: 39.2s\n",
            "888:\tlearn: 280.8872116\ttotal: 5m 11s\tremaining: 38.9s\n",
            "889:\tlearn: 280.8795622\ttotal: 5m 11s\tremaining: 38.5s\n",
            "890:\tlearn: 280.8739787\ttotal: 5m 12s\tremaining: 38.2s\n",
            "891:\tlearn: 280.8680541\ttotal: 5m 12s\tremaining: 37.9s\n",
            "892:\tlearn: 280.8555143\ttotal: 5m 13s\tremaining: 37.6s\n",
            "893:\tlearn: 280.8467564\ttotal: 5m 13s\tremaining: 37.2s\n",
            "894:\tlearn: 280.8369087\ttotal: 5m 14s\tremaining: 36.9s\n",
            "895:\tlearn: 280.8301170\ttotal: 5m 14s\tremaining: 36.5s\n",
            "896:\tlearn: 280.8242296\ttotal: 5m 15s\tremaining: 36.2s\n",
            "897:\tlearn: 280.8193821\ttotal: 5m 15s\tremaining: 35.8s\n",
            "898:\tlearn: 280.8136474\ttotal: 5m 15s\tremaining: 35.5s\n",
            "899:\tlearn: 280.8111724\ttotal: 5m 16s\tremaining: 35.1s\n",
            "900:\tlearn: 280.7961594\ttotal: 5m 16s\tremaining: 34.8s\n",
            "901:\tlearn: 280.7821995\ttotal: 5m 17s\tremaining: 34.4s\n",
            "902:\tlearn: 280.7749304\ttotal: 5m 17s\tremaining: 34.1s\n",
            "903:\tlearn: 280.7690534\ttotal: 5m 17s\tremaining: 33.7s\n",
            "904:\tlearn: 280.7643260\ttotal: 5m 18s\tremaining: 33.4s\n",
            "905:\tlearn: 280.7558543\ttotal: 5m 18s\tremaining: 33s\n",
            "906:\tlearn: 280.7498438\ttotal: 5m 19s\tremaining: 32.7s\n",
            "907:\tlearn: 280.7414206\ttotal: 5m 19s\tremaining: 32.4s\n",
            "908:\tlearn: 280.7348085\ttotal: 5m 20s\tremaining: 32.1s\n",
            "909:\tlearn: 280.7321313\ttotal: 5m 21s\tremaining: 31.8s\n",
            "910:\tlearn: 280.7238820\ttotal: 5m 22s\tremaining: 31.5s\n",
            "911:\tlearn: 280.7188318\ttotal: 5m 22s\tremaining: 31.1s\n",
            "912:\tlearn: 280.7118498\ttotal: 5m 23s\tremaining: 30.8s\n",
            "913:\tlearn: 280.7059560\ttotal: 5m 24s\tremaining: 30.5s\n",
            "914:\tlearn: 280.7010132\ttotal: 5m 24s\tremaining: 30.2s\n",
            "915:\tlearn: 280.6957733\ttotal: 5m 25s\tremaining: 29.9s\n",
            "916:\tlearn: 280.6924024\ttotal: 5m 26s\tremaining: 29.6s\n",
            "917:\tlearn: 280.6852964\ttotal: 5m 27s\tremaining: 29.3s\n",
            "918:\tlearn: 280.6806998\ttotal: 5m 28s\tremaining: 29s\n",
            "919:\tlearn: 280.6781122\ttotal: 5m 29s\tremaining: 28.6s\n",
            "920:\tlearn: 280.6749146\ttotal: 5m 29s\tremaining: 28.3s\n",
            "921:\tlearn: 280.6679775\ttotal: 5m 30s\tremaining: 28s\n",
            "922:\tlearn: 280.6612106\ttotal: 5m 31s\tremaining: 27.6s\n",
            "923:\tlearn: 280.6551705\ttotal: 5m 31s\tremaining: 27.3s\n",
            "924:\tlearn: 280.6481479\ttotal: 5m 32s\tremaining: 26.9s\n",
            "925:\tlearn: 280.6440363\ttotal: 5m 32s\tremaining: 26.6s\n",
            "926:\tlearn: 280.6342651\ttotal: 5m 33s\tremaining: 26.2s\n",
            "927:\tlearn: 280.6274442\ttotal: 5m 33s\tremaining: 25.9s\n",
            "928:\tlearn: 280.6217495\ttotal: 5m 33s\tremaining: 25.5s\n",
            "929:\tlearn: 280.6104390\ttotal: 5m 34s\tremaining: 25.1s\n",
            "930:\tlearn: 280.6018889\ttotal: 5m 34s\tremaining: 24.8s\n",
            "931:\tlearn: 280.5963811\ttotal: 5m 34s\tremaining: 24.4s\n",
            "932:\tlearn: 280.5888405\ttotal: 5m 35s\tremaining: 24.1s\n",
            "933:\tlearn: 280.5833280\ttotal: 5m 35s\tremaining: 23.7s\n",
            "934:\tlearn: 280.5776640\ttotal: 5m 35s\tremaining: 23.3s\n",
            "935:\tlearn: 280.5717372\ttotal: 5m 35s\tremaining: 23s\n",
            "936:\tlearn: 280.5646256\ttotal: 5m 36s\tremaining: 22.6s\n",
            "937:\tlearn: 280.5575838\ttotal: 5m 36s\tremaining: 22.2s\n",
            "938:\tlearn: 280.5534359\ttotal: 5m 36s\tremaining: 21.9s\n",
            "939:\tlearn: 280.5471752\ttotal: 5m 37s\tremaining: 21.5s\n",
            "940:\tlearn: 280.5372851\ttotal: 5m 37s\tremaining: 21.2s\n",
            "941:\tlearn: 280.5196355\ttotal: 5m 37s\tremaining: 20.8s\n",
            "942:\tlearn: 280.5152734\ttotal: 5m 38s\tremaining: 20.4s\n",
            "943:\tlearn: 280.5065525\ttotal: 5m 38s\tremaining: 20.1s\n",
            "944:\tlearn: 280.5008965\ttotal: 5m 38s\tremaining: 19.7s\n",
            "945:\tlearn: 280.4920088\ttotal: 5m 39s\tremaining: 19.4s\n",
            "946:\tlearn: 280.4848041\ttotal: 5m 39s\tremaining: 19s\n",
            "947:\tlearn: 280.4762846\ttotal: 5m 40s\tremaining: 18.7s\n",
            "948:\tlearn: 280.4700180\ttotal: 5m 40s\tremaining: 18.3s\n",
            "949:\tlearn: 280.4636095\ttotal: 5m 41s\tremaining: 18s\n",
            "950:\tlearn: 280.4467910\ttotal: 5m 41s\tremaining: 17.6s\n",
            "951:\tlearn: 280.4422137\ttotal: 5m 42s\tremaining: 17.3s\n",
            "952:\tlearn: 280.4359090\ttotal: 5m 42s\tremaining: 16.9s\n",
            "953:\tlearn: 280.4322967\ttotal: 5m 43s\tremaining: 16.6s\n",
            "954:\tlearn: 280.4285877\ttotal: 5m 43s\tremaining: 16.2s\n",
            "955:\tlearn: 280.4191504\ttotal: 5m 43s\tremaining: 15.8s\n",
            "956:\tlearn: 280.4129352\ttotal: 5m 44s\tremaining: 15.5s\n",
            "957:\tlearn: 280.4051223\ttotal: 5m 44s\tremaining: 15.1s\n",
            "958:\tlearn: 280.4006261\ttotal: 5m 44s\tremaining: 14.7s\n",
            "959:\tlearn: 280.3882521\ttotal: 5m 45s\tremaining: 14.4s\n",
            "960:\tlearn: 280.3807177\ttotal: 5m 45s\tremaining: 14s\n",
            "961:\tlearn: 280.3746761\ttotal: 5m 45s\tremaining: 13.7s\n",
            "962:\tlearn: 280.3500749\ttotal: 5m 46s\tremaining: 13.3s\n",
            "963:\tlearn: 280.3470030\ttotal: 5m 46s\tremaining: 12.9s\n",
            "964:\tlearn: 280.3361673\ttotal: 5m 46s\tremaining: 12.6s\n",
            "965:\tlearn: 280.3318566\ttotal: 5m 47s\tremaining: 12.2s\n",
            "966:\tlearn: 280.3203605\ttotal: 5m 47s\tremaining: 11.9s\n",
            "967:\tlearn: 280.3166743\ttotal: 5m 47s\tremaining: 11.5s\n",
            "968:\tlearn: 280.3126449\ttotal: 5m 48s\tremaining: 11.1s\n",
            "969:\tlearn: 280.3086424\ttotal: 5m 48s\tremaining: 10.8s\n",
            "970:\tlearn: 280.3054175\ttotal: 5m 48s\tremaining: 10.4s\n",
            "971:\tlearn: 280.2963440\ttotal: 5m 49s\tremaining: 10.1s\n",
            "972:\tlearn: 280.2931993\ttotal: 5m 49s\tremaining: 9.69s\n",
            "973:\tlearn: 280.2898467\ttotal: 5m 49s\tremaining: 9.33s\n",
            "974:\tlearn: 280.2850236\ttotal: 5m 49s\tremaining: 8.97s\n",
            "975:\tlearn: 280.2776679\ttotal: 5m 50s\tremaining: 8.61s\n",
            "976:\tlearn: 280.2715328\ttotal: 5m 50s\tremaining: 8.25s\n",
            "977:\tlearn: 280.2667333\ttotal: 5m 50s\tremaining: 7.89s\n",
            "978:\tlearn: 280.2613628\ttotal: 5m 51s\tremaining: 7.53s\n",
            "979:\tlearn: 280.2573306\ttotal: 5m 51s\tremaining: 7.17s\n",
            "980:\tlearn: 280.2506900\ttotal: 5m 51s\tremaining: 6.81s\n",
            "981:\tlearn: 280.2413220\ttotal: 5m 52s\tremaining: 6.45s\n",
            "982:\tlearn: 280.2365542\ttotal: 5m 52s\tremaining: 6.09s\n",
            "983:\tlearn: 280.2297921\ttotal: 5m 52s\tremaining: 5.74s\n",
            "984:\tlearn: 280.2238743\ttotal: 5m 53s\tremaining: 5.38s\n",
            "985:\tlearn: 280.2118274\ttotal: 5m 53s\tremaining: 5.02s\n",
            "986:\tlearn: 280.2057651\ttotal: 5m 54s\tremaining: 4.67s\n",
            "987:\tlearn: 280.2000315\ttotal: 5m 54s\tremaining: 4.31s\n",
            "988:\tlearn: 280.1969945\ttotal: 5m 55s\tremaining: 3.95s\n",
            "989:\tlearn: 280.1905895\ttotal: 5m 55s\tremaining: 3.6s\n",
            "990:\tlearn: 280.1865736\ttotal: 5m 56s\tremaining: 3.24s\n",
            "991:\tlearn: 280.1816308\ttotal: 5m 56s\tremaining: 2.88s\n",
            "992:\tlearn: 280.1758802\ttotal: 5m 57s\tremaining: 2.52s\n",
            "993:\tlearn: 280.1708144\ttotal: 5m 57s\tremaining: 2.16s\n",
            "994:\tlearn: 280.1661385\ttotal: 5m 57s\tremaining: 1.8s\n",
            "995:\tlearn: 280.1619500\ttotal: 5m 58s\tremaining: 1.44s\n",
            "996:\tlearn: 280.1598213\ttotal: 5m 58s\tremaining: 1.08s\n",
            "997:\tlearn: 280.1569212\ttotal: 5m 58s\tremaining: 719ms\n",
            "998:\tlearn: 280.1516149\ttotal: 5m 59s\tremaining: 359ms\n",
            "999:\tlearn: 280.1418415\ttotal: 5m 59s\tremaining: 0us\n",
            "CatBoost Mean Squared Error: 79203.26976685596\n",
            "CatBoost Root Mean Squared Error: 281.43075483474786\n",
            "CatBoost Mean Absolute Error: 143.8872697268587\n",
            "CatBoost Root Mean Squared Logarithmic Error: 0.02946236912914856\n",
            "CatBoost R-squared: 0.8749272674211922\n",
            "CatBoost Mean Absolute Percentage Error: 35.44426582668714\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Rfto17TOB-OH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}